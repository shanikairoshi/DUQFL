{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shanikairoshi/DUQFL/blob/main/DQFL_Genome_non_IID.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdPhLlT9q3Np"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxxcEJUXUwSy",
        "outputId": "7e0c6961-2fdc-472e-eddb-d18b3f990588"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Mar 30 20:39:21 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyDoDOITVFmd",
        "outputId": "80c9e753-0140-40fd-ba06-bc61177db0e9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Us3DV6Sfq6Mw"
      },
      "outputs": [],
      "source": [
        "\n",
        "%%capture\n",
        "!pip install genomic-benchmarks\n",
        "!pip install qiskit qiskit_machine_learning qiskit_algorithms\n",
        "!pip install qiskit-aer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "er-_TE10rI2c"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install qiskit\n",
        "!pip install qiskit_machine_learning\n",
        "!pip install qiskit-aer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m5M_eDObB6OI"
      },
      "outputs": [],
      "source": [
        "#-------Split data for federated Setting--------#\n",
        "num_epochs = 10 #50\n",
        "max_train_iterations = 100\n",
        "samples_per_epoch=100 #10\n",
        "#backend = Aer.get_backend('aer_simulator')\n",
        "word_size = 40\n",
        "\n",
        "# Configuration variables\n",
        "num_clients = 5\n",
        "num_federated_layers = 10\n",
        "num_deep_unfolding_iterations = 8\n",
        "initial_learning_rate = 0.15\n",
        "meta_learning_rate=1e-4\n",
        "initial_perturbation = 0.15\n",
        "momentum = 0.95\n",
        "gradient_moving_avg = 0\n",
        "\n",
        "# Define federated learning with accuracy tracking\n",
        "num_features = 5\n",
        "global_model_weights, global_model_accuracy = {}, []\n",
        "clients_train_accuracies, clients_test_accuracies = [], []\n",
        "\n",
        "# Define the federated learning parameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total needed=num_clients×num_epochs×samples_per_epoch\n",
        "➤ For your configuration:\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "num_clients = 8\n",
        "num_epochs = 10\n",
        "samples_per_epoch = 100\n",
        "8\n",
        "×\n",
        "10\n",
        "×\n",
        "100\n",
        "=\n",
        "8000\n",
        " training samples needed\n",
        "8×10×100=8000 training samples needed"
      ],
      "metadata": {
        "id": "9IsDsINe6ut4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpAw5S3imZQW",
        "outputId": "e5d49789-2943-4952-c712-6fcb35019f12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nuber of samples in the test set: 25000\n",
            "Nuber of samples in the test set: 75000\n",
            "First sample int the data_set variable: \n",
            "('AATGGATAATTTTTTTATTTTTTCAACCAGGAGAATTTCGGTGCAACGAAAACGCATGTGCATTTTGATCTACCTGCATTGCGACAAGCCTTACAGCAACAACGAAGACTGGTCGATTCAAGCTGAAGTACATCTTATTTTGGTTTCAGACACAGGAAGAACATCTACTGATAGGGTCACTCACATTTTCGAAAAACCAG', 0)\n",
            "\n",
            "First 5 samples in the word_combinations dict.\n",
            "AATG 1\n",
            "ATGG 2\n",
            "TGGA 3\n",
            "GGAT 4\n",
            "GATA 5\n",
            "First 5 samples of encoded data:\n",
            "First 5 samples of encoded shuffled data:\n",
            "First 5 samples of scaled encoded shuffled data:\n",
            "Length of np_train_data: 8000\n",
            "Length of np_test_data: 1000\n",
            "Number of samples in the test set: 25000\n",
            "Number of samples in the train set: 75000\n",
            "First sample in the data_set variable: \n",
            "('AATGGATAATTTTTTTATTTTTTCAACCAGGAGAATTTCGGTGCAACGAAAACGCATGTGCATTTTGATCTACCTGCATTGCGACAAGCCTTACAGCAACAACGAAGACTGGTCGATTCAAGCTGAAGTACATCTTATTTTGGTTTCAGACACAGGAAGAACATCTACTGATAGGGTCACTCACATTTTCGAAAAACCAG', 0)\n",
            "\n",
            "First 5 samples in the word_combinations dict.\n",
            "AATGG 1\n",
            "ATGGA 2\n",
            "TGGAT 3\n",
            "GGATA 4\n",
            "GATAA 5\n",
            "First 5 samples of encoded data:\n",
            "[{'sequence': array([ 1,  6, 10, 14, 16]), 'label': 0}, {'sequence': array([165, 169, 174, 178, 182]), 'label': 0}, {'sequence': array([316, 263, 193, 324, 326]), 'label': 0}, {'sequence': array([442, 297, 449, 341,  10]), 'label': 0}, {'sequence': array([ 17,  27, 275, 503, 479]), 'label': 0}]\n",
            "First 5 samples of encoded shuffled data:\n",
            "[{'sequence': array([1003,  583,  306,   94,  326]), 'label': 1}, {'sequence': array([271, 740,  54, 246, 372]), 'label': 1}, {'sequence': array([740, 806, 729, 293, 180]), 'label': 1}, {'sequence': array([577, 524,  58, 674, 324]), 'label': 1}, {'sequence': array([631, 462,   3, 188, 744]), 'label': 0}]\n",
            "First 5 samples of scaled encoded shuffled data:\n",
            "[{'sequence': array([0.73460411, 0.42481752, 0.22360704, 0.06818182, 0.23826979]), 'label': 1}, {'sequence': array([0.19794721, 0.53941606, 0.0388563 , 0.17961877, 0.27199413]), 'label': 1}, {'sequence': array([0.54178886, 0.58759124, 0.53372434, 0.21407625, 0.13123167]), 'label': 1}, {'sequence': array([0.42228739, 0.38175182, 0.04178886, 0.49340176, 0.23680352]), 'label': 1}, {'sequence': array([0.46187683, 0.33649635, 0.00146628, 0.13709677, 0.54472141]), 'label': 0}]\n",
            "Length of np_train_data: 8000\n",
            "Length of np_test_data: 1000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from genomic_benchmarks.dataset_getters.pytorch_datasets import DemoHumanOrWorm\n",
        "import time\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit_algorithms.optimizers import COBYLA\n",
        "from qiskit_machine_learning.algorithms.classifiers import VQC\n",
        "from qiskit.primitives import BackendSampler\n",
        "from functools import partial\n",
        "from qiskit_aer import Aer\n",
        "\n",
        "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
        "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit.primitives import BackendSampler\n",
        "from qiskit_algorithms.optimizers import SPSA\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "from qiskit_algorithms.utils import algorithm_globals # Import algorithm_globals\n",
        "\n",
        "# Set random seed for reproducibility using algorithm_globals\n",
        "algorithm_globals.random_seed = 42  # Set seed globally\n",
        "\n",
        "\n",
        "test_set = DemoHumanOrWorm(split='test', version=0)\n",
        "train_set = DemoHumanOrWorm(split='train', version=0)\n",
        "\n",
        "data_set = train_set\n",
        "# data_set = train_set + test_set\n",
        "len(data_set)\n",
        "\n",
        "\n",
        "print(f\"Nuber of samples in the test set: {len(test_set)}\")\n",
        "print(f\"Nuber of samples in the test set: {len(train_set)}\")\n",
        "\n",
        "from genomic_benchmarks.dataset_getters.pytorch_datasets import DemoHumanOrWorm\n",
        "\n",
        "test_set = DemoHumanOrWorm(split='test', version=0)\n",
        "train_set = DemoHumanOrWorm(split='train', version=0)\n",
        "\n",
        "data_set = train_set\n",
        "# data_set = train_set + test_set\n",
        "len(data_set)\n",
        "\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "word_combinations = defaultdict(int)\n",
        "iteration = 1\n",
        "for text, _ in data_set:\n",
        "    for i in range(len(text)):\n",
        "        word = text[i:i+word_size]\n",
        "        if word_combinations.get(word) is None:\n",
        "          word_combinations[word] = iteration\n",
        "          iteration += 1\n",
        "\n",
        "\n",
        "\n",
        "print(\"First sample int the data_set variable: \")\n",
        "print(data_set[0])\n",
        "\n",
        "print(\"\\nFirst 5 samples in the word_combinations dict.\")\n",
        "for key, value in list(word_combinations.items())[:5]:\n",
        "    print(key, value)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "# Preprocess the training set\n",
        "np_data_set = []\n",
        "for i in range(len(data_set)):\n",
        "    sequence, label = data_set[i]\n",
        "    sequence = sequence.strip()  # Remove any leading/trailing whitespace\n",
        "    words = [sequence[i:i + word_size] for i in range(0, len(sequence), word_size)]  # Split the sequence into 4-letter words\n",
        "    int_sequence = np.array([word_combinations[word] for word in words])\n",
        "    data_point = {'sequence': int_sequence, 'label': label}\n",
        "    np_data_set.append(data_point)\n",
        "\n",
        "\n",
        "print(\"First 5 samples of encoded data:\")\n",
        "np_data_set[:5]\n",
        "\n",
        "\n",
        "np.random.shuffle(np_data_set)\n",
        "print(\"First 5 samples of encoded shuffled data:\")\n",
        "np_data_set[:5]\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "sequences = np.array([item['sequence'] for item in np_data_set])\n",
        "sequences = np.vstack(sequences)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "sequences_scaled = scaler.fit_transform(sequences)\n",
        "\n",
        "for i, item in enumerate(np_data_set):\n",
        "    item['sequence'] = sequences_scaled[i]\n",
        "\n",
        "print(\"First 5 samples of scaled encoded shuffled data:\")\n",
        "np_data_set[:5]\n",
        "\n",
        "\n",
        "np_train_data = np_data_set[:8000]\n",
        "np_test_data = np_data_set[-1000:]\n",
        "\n",
        "print(f\"Length of np_train_data: {len(np_train_data)}\")\n",
        "print(f\"Length of np_test_data: {len(np_test_data)}\")\n",
        "\n",
        "test_sequences = [data_point[\"sequence\"] for data_point in np_test_data]\n",
        "test_labels = [data_point[\"label\"] for data_point in np_test_data]\n",
        "test_sequences = np.array(test_sequences)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "\n",
        "#---------------------------------------\n",
        "from genomic_benchmarks.dataset_getters.pytorch_datasets import DemoHumanOrWorm\n",
        "import time\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit_algorithms.optimizers import COBYLA\n",
        "from qiskit_machine_learning.algorithms.classifiers import VQC\n",
        "from qiskit.primitives import BackendSampler\n",
        "from functools import partial\n",
        "from qiskit_aer import Aer\n",
        "\n",
        "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
        "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit.primitives import BackendSampler\n",
        "from qiskit_algorithms.optimizers import SPSA\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "from qiskit_algorithms.utils import algorithm_globals # Import algorithm_globals\n",
        "\n",
        "# Set random seed for reproducibility using algorithm_globals\n",
        "algorithm_globals.random_seed = 42  # Set seed globally\n",
        "\n",
        "\n",
        "test_set = DemoHumanOrWorm(split='test', version=0)\n",
        "train_set = DemoHumanOrWorm(split='train', version=0)\n",
        "\n",
        "data_set = train_set\n",
        "# data_set = train_set + test_set\n",
        "len(data_set)\n",
        "\n",
        "\n",
        "print(f\"Number of samples in the test set: {len(test_set)}\")\n",
        "print(f\"Number of samples in the train set: {len(train_set)}\")\n",
        "\n",
        "from genomic_benchmarks.dataset_getters.pytorch_datasets import DemoHumanOrWorm\n",
        "\n",
        "test_set = DemoHumanOrWorm(split='test', version=0)\n",
        "train_set = DemoHumanOrWorm(split='train', version=0)\n",
        "\n",
        "data_set = train_set\n",
        "# data_set = train_set + test_set\n",
        "len(data_set)\n",
        "\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "word_size = 5 # Define word_size\n",
        "word_combinations = defaultdict(int)\n",
        "iteration = 1\n",
        "for text, _ in data_set:\n",
        "    for i in range(len(text)):\n",
        "        word = text[i:i+word_size]\n",
        "        if word_combinations.get(word) is None:\n",
        "          word_combinations[word] = iteration\n",
        "          iteration += 1\n",
        "\n",
        "\n",
        "\n",
        "print(\"First sample in the data_set variable: \")\n",
        "print(data_set[0])\n",
        "\n",
        "print(\"\\nFirst 5 samples in the word_combinations dict.\")\n",
        "for key, value in list(word_combinations.items())[:5]:\n",
        "    print(key, value)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "# Preprocess the training set\n",
        "np_data_set = []\n",
        "for i in range(len(data_set)):\n",
        "    sequence, label = data_set[i]\n",
        "    sequence = sequence.strip()  # Remove any leading/trailing whitespace\n",
        "    words = [sequence[i:i + word_size] for i in range(0, len(sequence), word_size)]  # Split the sequence into 4-letter words\n",
        "    int_sequence = np.array([word_combinations[word] for word in words])\n",
        "    data_point = {'sequence': int_sequence, 'label': label}\n",
        "    np_data_set.append(data_point)\n",
        "\n",
        "for i, item in enumerate(np_data_set):\n",
        "    sequence = item['sequence']\n",
        "    if len(sequence) < 5:  # If shorter than 5, pad with zeros\n",
        "        item['sequence'] = np.pad(sequence, (0, 5 - len(sequence)), 'constant', constant_values=0)\n",
        "    elif len(sequence) > 5:  # If longer than 5, truncate\n",
        "        item['sequence'] = sequence[:5]\n",
        "\n",
        "print(\"First 5 samples of encoded data:\")\n",
        "print(np_data_set[:5])\n",
        "\n",
        "\n",
        "np.random.shuffle(np_data_set)\n",
        "print(\"First 5 samples of encoded shuffled data:\")\n",
        "print(np_data_set[:5])\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "sequences = np.array([item['sequence'] for item in np_data_set])\n",
        "sequences = np.vstack(sequences)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "sequences_scaled = scaler.fit_transform(sequences)\n",
        "\n",
        "for i, item in enumerate(np_data_set):\n",
        "    item['sequence'] = sequences_scaled[i]\n",
        "\n",
        "print(\"First 5 samples of scaled encoded shuffled data:\")\n",
        "print(np_data_set[:5])\n",
        "\n",
        "\n",
        "np_train_data = np_data_set[:8000]\n",
        "np_test_data = np_data_set[-1000:]\n",
        "\n",
        "print(f\"Length of np_train_data: {len(np_train_data)}\")\n",
        "print(f\"Length of np_test_data: {len(np_test_data)}\")\n",
        "\n",
        "test_sequences = [data_point[\"sequence\"] for data_point in np_test_data]\n",
        "test_labels = [data_point[\"label\"] for data_point in np_test_data]\n",
        "test_sequences = np.array(test_sequences)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "\n",
        "#---------------------------------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "def split_dataset(num_clients, num_epochs, samples_per_epoch):\n",
        "    clients = []\n",
        "    # Split test data across clients\n",
        "    test_samples_per_client = len(np_test_data) // num_clients\n",
        "\n",
        "    for i in range(num_clients):\n",
        "        client_data = []\n",
        "        for j in range(num_epochs):\n",
        "            start_idx = (i * num_epochs * samples_per_epoch) + (j * samples_per_epoch)\n",
        "            end_idx = (i * num_epochs * samples_per_epoch) + ((j + 1) * samples_per_epoch)\n",
        "            client_data.append(np_train_data[start_idx:end_idx])\n",
        "\n",
        "        # Assign a subset of the test data to each client\n",
        "        test_start_idx = i * test_samples_per_client\n",
        "        test_end_idx = (i + 1) * test_samples_per_client\n",
        "        client_test_data = np_test_data[test_start_idx:test_end_idx]\n",
        "\n",
        "        # Create Client instance with both train and test data\n",
        "        clients.append(Client(client_data, client_test_data))\n",
        "\n",
        "    return clients\n",
        "\n",
        "clients = split_dataset(num_clients, num_epochs, samples_per_epoch)\n",
        "\n",
        "# Verify test data distribution across clients\n",
        "for index, client in enumerate(clients):\n",
        "    print(f\"Client {index} Test Data Length: {len(client.test_data)}\")\n",
        "    clients = []\n",
        "    # Split test data across clients\n",
        "    test_samples_per_client = len(np_test_data) // num_clients\n",
        "\n",
        "    for i in range(num_clients):\n",
        "        client_data = []\n",
        "        for j in range(num_epochs):\n",
        "            start_idx = (i * num_epochs * samples_per_epoch) + (j * samples_per_epoch)\n",
        "            end_idx = (i * num_epochs * samples_per_epoch) + ((j + 1) * samples_per_epoch)\n",
        "            client_data.append(np_train_data[start_idx:end_idx])\n",
        "\n",
        "        # Assign a subset of the test data to each client\n",
        "        test_start_idx = i * test_samples_per_client\n",
        "        test_end_idx = (i + 1) * test_samples_per_client\n",
        "        client_test_data = np_test_data[test_start_idx:test_end_idx]\n",
        "\n",
        "        # Create Client instance with both train and test data\n",
        "        clients.append(Client(client_data, client_test_data))\n",
        "\n",
        "    return clients\n",
        "\n",
        "clients = split_dataset(num_clients, num_epochs, samples_per_epoch)\n",
        "\n",
        "# Verify test data distribution across clients\n",
        "for index, client in enumerate(clients):\n",
        "    print(f\"Client {index} Test Data Length: {len(client.test_data)}\")\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "cCU9OSfV4I6c",
        "outputId": "089c57e9-d3a7-4836-a14c-7fdb363d67ee"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef split_dataset(num_clients, num_epochs, samples_per_epoch):\\n    clients = []\\n    # Split test data across clients\\n    test_samples_per_client = len(np_test_data) // num_clients\\n\\n    for i in range(num_clients):\\n        client_data = []\\n        for j in range(num_epochs):\\n            start_idx = (i * num_epochs * samples_per_epoch) + (j * samples_per_epoch)\\n            end_idx = (i * num_epochs * samples_per_epoch) + ((j + 1) * samples_per_epoch)\\n            client_data.append(np_train_data[start_idx:end_idx])\\n\\n        # Assign a subset of the test data to each client\\n        test_start_idx = i * test_samples_per_client\\n        test_end_idx = (i + 1) * test_samples_per_client\\n        client_test_data = np_test_data[test_start_idx:test_end_idx]\\n\\n        # Create Client instance with both train and test data\\n        clients.append(Client(client_data, client_test_data))\\n\\n    return clients\\n\\nclients = split_dataset(num_clients, num_epochs, samples_per_epoch)\\n\\n# Verify test data distribution across clients\\nfor index, client in enumerate(clients):\\n    print(f\"Client {index} Test Data Length: {len(client.test_data)}\")\\n    clients = []\\n    # Split test data across clients\\n    test_samples_per_client = len(np_test_data) // num_clients\\n\\n    for i in range(num_clients):\\n        client_data = []\\n        for j in range(num_epochs):\\n            start_idx = (i * num_epochs * samples_per_epoch) + (j * samples_per_epoch)\\n            end_idx = (i * num_epochs * samples_per_epoch) + ((j + 1) * samples_per_epoch)\\n            client_data.append(np_train_data[start_idx:end_idx])\\n\\n        # Assign a subset of the test data to each client\\n        test_start_idx = i * test_samples_per_client\\n        test_end_idx = (i + 1) * test_samples_per_client\\n        client_test_data = np_test_data[test_start_idx:test_end_idx]\\n\\n        # Create Client instance with both train and test data\\n        clients.append(Client(client_data, client_test_data))\\n\\n    return clients\\n\\nclients = split_dataset(num_clients, num_epochs, samples_per_epoch)\\n\\n# Verify test data distribution across clients\\nfor index, client in enumerate(clients):\\n    print(f\"Client {index} Test Data Length: {len(client.test_data)}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = set()\n",
        "for sample in np_train_data:\n",
        "    labels.add(sample['label'])\n",
        "\n",
        "print(f\"Number of unique labels: {len(labels)}\")\n",
        "print(f\"Labels: {labels}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sggx8VvxbG6F",
        "outputId": "da682bea-7e4e-4da8-d01a-812034b3e47b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique labels: 2\n",
            "Labels: {0, 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MkdB4QRUaIJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import rel_entr\n",
        "\n",
        "def kl_divergence(p, q):\n",
        "    p = np.asarray(p, dtype=np.float32)\n",
        "    q = np.asarray(q, dtype=np.float32)\n",
        "    return np.sum(rel_entr(p, q))\n",
        "\n",
        "def label_distribution(client):\n",
        "    labels = [sample['label'] for epoch in client.data for sample in epoch]\n",
        "    label_counts = Counter(labels)\n",
        "    total = sum(label_counts.values())\n",
        "    dist = [label_counts.get(i, 0) / total for i in range(len(set(label_counts)))]\n",
        "    return dist\n",
        "\n",
        "for i in range(len(clients)):\n",
        "    for j in range(i + 1, len(clients)):\n",
        "        dist_i = label_distribution(clients[i])\n",
        "        dist_j = label_distribution(clients[j])\n",
        "        kl_ij = kl_divergence(dist_i, dist_j)\n",
        "        kl_ji = kl_divergence(dist_j, dist_i)\n",
        "        print(f\"KL(Client {i} || Client {j}) = {kl_ij:.4f}, KL(Client {j} || Client {i}) = {kl_ji:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgYp9EycaCzc",
        "outputId": "62cf4655-ce22-45e9-9ab8-92ed1ba379c7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KL(Client 0 || Client 1) = 0.0000, KL(Client 1 || Client 0) = 0.0000\n",
            "KL(Client 0 || Client 2) = 0.0000, KL(Client 2 || Client 0) = 0.0000\n",
            "KL(Client 0 || Client 3) = 0.0018, KL(Client 3 || Client 0) = 0.0018\n",
            "KL(Client 0 || Client 4) = 0.0000, KL(Client 4 || Client 0) = 0.0000\n",
            "KL(Client 1 || Client 2) = 0.0001, KL(Client 2 || Client 1) = 0.0001\n",
            "KL(Client 1 || Client 3) = 0.0015, KL(Client 3 || Client 1) = 0.0015\n",
            "KL(Client 1 || Client 4) = 0.0001, KL(Client 4 || Client 1) = 0.0001\n",
            "KL(Client 2 || Client 3) = 0.0022, KL(Client 3 || Client 2) = 0.0022\n",
            "KL(Client 2 || Client 4) = 0.0000, KL(Client 4 || Client 2) = 0.0000\n",
            "KL(Client 3 || Client 4) = 0.0020, KL(Client 4 || Client 3) = 0.0021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We apply partial label skew here"
      ],
      "metadata": {
        "id": "VyG9MVY-bThg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def split_dataset_partial_label_skew(num_clients, major_label_ratio=0.8, samples_per_client=1000):\n",
        "    from collections import defaultdict\n",
        "    import random\n",
        "\n",
        "    # Separate training data by label\n",
        "    label_buckets = defaultdict(list)\n",
        "    for sample in np_train_data:\n",
        "        label_buckets[sample['label']].append(sample)\n",
        "\n",
        "    # Shuffle each label bucket\n",
        "    for label in label_buckets:\n",
        "        random.shuffle(label_buckets[label])\n",
        "\n",
        "    clients = []\n",
        "    labels = list(label_buckets.keys())\n",
        "\n",
        "    for i in range(num_clients):\n",
        "        major_label = labels[i % len(labels)]  # Assign majority label per client\n",
        "        minor_label = labels[(i + 1) % len(labels)]  # Other label\n",
        "\n",
        "        num_major = int(major_label_ratio * samples_per_client)\n",
        "        num_minor = samples_per_client - num_major\n",
        "\n",
        "        # Sample data\n",
        "        major_samples = label_buckets[major_label][:num_major]\n",
        "        minor_samples = label_buckets[minor_label][:num_minor]\n",
        "\n",
        "        # Remove assigned samples from the buckets\n",
        "        label_buckets[major_label] = label_buckets[major_label][num_major:]\n",
        "        label_buckets[minor_label] = label_buckets[minor_label][num_minor:]\n",
        "\n",
        "        client_data = major_samples + minor_samples\n",
        "        random.shuffle(client_data)\n",
        "\n",
        "        # Assign test data (can be IID)\n",
        "        test_data = np_test_data[i * 500:(i + 1) * 500]\n",
        "\n",
        "        clients.append(Client(data=[client_data], test_data=test_data))\n",
        "\n",
        "    return clients\n",
        "'''"
      ],
      "metadata": {
        "id": "n1Sfe4e9l3Q7"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "class Client:  # Define the Client class\n",
        "    def __init__(self, data, test_data):\n",
        "        self.data = data\n",
        "        self.test_data = test_data\n",
        "        self.primary_model = None  # Add primary_model attribute\n",
        "\n",
        "\n",
        "\n",
        "def split_dataset_label_skew(num_clients):\n",
        "    # Separate by label\n",
        "    label_buckets = defaultdict(list)\n",
        "    for sample in np_train_data:\n",
        "        label_buckets[sample['label']].append(sample)\n",
        "\n",
        "    # Shuffle each bucket\n",
        "    for label in label_buckets:\n",
        "        random.shuffle(label_buckets[label])\n",
        "\n",
        "    clients = []\n",
        "    labels = list(label_buckets.keys())\n",
        "\n",
        "    # Assign specific label(s) to each client\n",
        "    for i in range(num_clients):\n",
        "        label_to_use = labels[i % len(labels)]  # e.g., alternate between 0 and 1\n",
        "        client_data = label_buckets[label_to_use][:1000]  # pick 1000 samples of that label\n",
        "        label_buckets[label_to_use] = label_buckets[label_to_use][1000:]  # remove assigned\n",
        "\n",
        "        # Sample test data (could remain IID)\n",
        "        test_data = np_test_data[i * 500:(i + 1) * 500]\n",
        "        clients.append(Client(data=[client_data], test_data=test_data))\n",
        "\n",
        "    return clients\n"
      ],
      "metadata": {
        "id": "AfL5uxMgbTFG"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "clients = split_dataset_label_skew(num_clients)\n",
        "\n",
        "def plot_label_distribution(clients):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for idx, client in enumerate(clients):\n",
        "        labels = [sample['label'] for epoch in client.data for sample in epoch]\n",
        "        label_counts = Counter(labels)\n",
        "        labels_sorted = sorted(label_counts.keys())\n",
        "        counts = [label_counts[label] for label in labels_sorted]\n",
        "\n",
        "        plt.bar(\n",
        "            [str(label) + f\"_C{idx}\" for label in labels_sorted],\n",
        "            counts,\n",
        "            label=f'Client {idx}'\n",
        "        )\n",
        "\n",
        "    plt.xlabel(\"Label per Client\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.title(\"Label Distribution per Client (Training Data)\")\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_label_distribution(clients)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "s9YljT5Gyblu",
        "outputId": "970b4a60-1e3a-48db-c8fa-5abbbe6b6d98"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rvulq9UfzHae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIg_mUrp3_2J"
      },
      "source": [
        "Data Load and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "3OTrftC6uZd_"
      },
      "outputs": [],
      "source": [
        "def split_dataset_for_epochs(num_clients, num_epochs, train_data, test_data, samples_per_epoch):\n",
        "    \"\"\"\n",
        "    Split the dataset across multiple epochs and clients.\n",
        "\n",
        "    Args:\n",
        "        num_clients (int): Number of clients.\n",
        "        num_epochs (int): Number of epochs.\n",
        "        train_data (list): List of training data points.\n",
        "        test_data (list): List of test data points.\n",
        "        samples_per_epoch (int): Number of samples per epoch.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of Client objects with assigned data for each epoch.\n",
        "    \"\"\"\n",
        "    clients = []\n",
        "\n",
        "    # Split the training data across epochs and clients\n",
        "    train_samples_per_client = len(train_data) // num_clients\n",
        "\n",
        "    for i in range(num_clients):\n",
        "        client_data_for_epochs = []\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            start_idx = (i * num_epochs * samples_per_epoch) + (epoch * samples_per_epoch)\n",
        "            end_idx = (i * num_epochs * samples_per_epoch) + ((epoch + 1) * samples_per_epoch)\n",
        "            client_data_for_epochs.append(train_data[start_idx:end_idx])\n",
        "\n",
        "        # Assign test data to each client\n",
        "        test_samples_per_client = len(test_data) // num_clients\n",
        "        test_start_idx = i * test_samples_per_client\n",
        "        test_end_idx = (i + 1) * test_samples_per_client\n",
        "        client_test_data = test_data[test_start_idx:test_end_idx]\n",
        "\n",
        "        # Create a Client instance with epoch-specific data\n",
        "        clients.append(Client(client_data_for_epochs, client_test_data))\n",
        "\n",
        "    return clients\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "#clients = split_dataset_label_skew(num_clients)\n",
        "\n",
        "def plot_label_distribution(clients):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for idx, client in enumerate(clients):\n",
        "        labels = [sample['label'] for epoch in client.data for sample in epoch]\n",
        "        label_counts = Counter(labels)\n",
        "        labels_sorted = sorted(label_counts.keys())\n",
        "        counts = [label_counts[label] for label in labels_sorted]\n",
        "\n",
        "        plt.bar(\n",
        "            [str(label) + f\"_C{idx}\" for label in labels_sorted],\n",
        "            counts,\n",
        "            label=f'Client {idx}'\n",
        "        )\n",
        "\n",
        "    plt.xlabel(\"Label per Client\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.title(\"Label Distribution per Client (Training Data)\")\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_label_distribution(clients)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "dbhFuwRiz1O2",
        "outputId": "29b89527-60cf-46f7-86f8-b2c2f41c5a22"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "vHHwtTUF65Gp"
      },
      "outputs": [],
      "source": [
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
        "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit.primitives import BackendSampler\n",
        "from qiskit_algorithms.optimizers import SPSA\n",
        "from qiskit_algorithms.utils import algorithm_globals\n",
        "from qiskit_algorithms.optimizers import COBYLA\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import log_loss\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Callback function to capture the loss values\n",
        "objective_func_vals = []  # Global list to store loss values\n",
        "learning_rates = []\n",
        "perturbations = []\n",
        "# Data structure for tracking per-client, per-layer objective function values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "o0CaYcz9FQw7"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os  # For handling directories\n",
        "\n",
        "# Define the directory to save the plots\n",
        "output_dir = \"federated_round_plots\"\n",
        "os.makedirs(output_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
        "# Initialize a global variable to track the round number\n",
        "current_round = 1\n",
        "\n",
        "# Callback for visualization, gradient smoothing, and learning rate adjustment in deep unfolding\n",
        "def deep_unfolding_learning_rate_adjustment(parameters, obj_func_eval, gradients=None,round_number=0):\n",
        "    global gradient_moving_avg, learning_rates, perturbations,current_round\n",
        "\n",
        "    clear_output(wait=True)\n",
        "\n",
        "    # Save the objective function value for visualization\n",
        "    objective_func_vals.append(obj_func_eval)\n",
        "\n",
        "    # If gradients are provided, smooth the gradient using momentum\n",
        "    if gradients is not None:\n",
        "        gradient_moving_avg = momentum * gradient_moving_avg + (1 - momentum) * gradients  # Apply moving average\n",
        "        delta_lr = 0.05 * gradient_moving_avg  # Adjust learning rate based on the smoothed gradient\n",
        "        delta_perturbation = 0.1 * gradient_moving_avg  # Adjust perturbation based on the same gradient\n",
        "    else:\n",
        "        delta_lr = 0  # No gradient info available in this iteration\n",
        "        delta_perturbation = 0\n",
        "\n",
        "    # Update learning rate and perturbation\n",
        "    if len(learning_rates) > 0:\n",
        "        new_lr = max(0.001, learning_rates[-1] + delta_lr)  # Ensure learning rate is positive and non-zero\n",
        "        new_perturbation = max(0.001, perturbations[-1] + delta_perturbation)  # Ensure perturbation is positive\n",
        "    else:\n",
        "        new_lr = initial_learning_rate\n",
        "        new_perturbation = initial_perturbation\n",
        "\n",
        "    learning_rates.append(new_lr)\n",
        "    perturbations.append(new_perturbation)\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # Visualization of learning rate and perturbation\n",
        "    plt.figure(figsize=(10, 12))  # Adjust figure size for better spacing\n",
        "\n",
        "    # Plot Objective Function Value\n",
        "    plt.subplot(3, 1, 1)\n",
        "    plt.plot(range(len(objective_func_vals)), objective_func_vals, label=\"Objective Function Value\", color='blue')\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Objective Function Value\")\n",
        "    plt.title(\"Objective Function Over Iterations\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.grid(True)  # Add grid for better readability\n",
        "\n",
        "    # Plot Learning Rate\n",
        "    plt.subplot(3, 1, 2)\n",
        "    plt.plot(range(len(learning_rates)), learning_rates, label=\"Learning Rate\", color='green')\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Learning Rate\")\n",
        "    plt.title(\"Learning Rate Over Iterations\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot Perturbation\n",
        "    plt.subplot(3, 1, 3)\n",
        "    plt.plot(range(len(perturbations)), perturbations, label=\"Perturbation\", color='red')\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Perturbation\")\n",
        "    plt.title(\"Perturbation Over Iterations\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout(pad=3.0)  # Add padding between subplots\n",
        "    # Save the plot after each federated round\n",
        "    #plot_filename = os.path.join(output_dir, f\"federated_round_{current_round}.png\")\n",
        "    #plt.savefig(plot_filename)  # Save the figure\n",
        "    #plt.show()\n",
        "    plt.close()  # Close the plot to free memory\n",
        "\n",
        "    # Increment the round number for the next call\n",
        "    current_round += 1\n",
        "\n",
        "\n",
        "# Define the SPSA callback to capture gradients and update learning rate and perturbation dynamically\n",
        "def spsa_callback(nfev, parameters, obj_func_eval, stepsize, accept):\n",
        "    # Assuming `stepsize` contains gradient information or its approximation\n",
        "    gradients = stepsize\n",
        "    deep_unfolding_learning_rate_adjustment(parameters, obj_func_eval, gradients)\n",
        "\n",
        "# Custom SPSA optimizer with learnable learning rate and perturbation\n",
        "class LearnableLRPerturbationSPSA(SPSA):\n",
        "    def __init__(self, initial_lr=1e-4, initial_perturbation=0.01, lr_alpha=0.1, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.lr = initial_lr  # Initial learning rate\n",
        "        self.perturbation = initial_perturbation  # Initial perturbation\n",
        "        self.lr_alpha = lr_alpha  # Learning rate and perturbation update speed\n",
        "\n",
        "    def _update_learning_rate_and_perturbation(self, gradient, obj_func_eval):\n",
        "        \"\"\"\n",
        "        Update both learning rate and perturbation based on gradient and objective function evaluation.\n",
        "        The learning rate increases if the objective function improves and decreases otherwise.\n",
        "        \"\"\"\n",
        "        # Use the gradient sign to determine if we should increase or decrease\n",
        "        grad_lr = np.sign(np.mean(gradient))  # Average gradient sign across parameters\n",
        "\n",
        "        if grad_lr > 0:  # Objective function is improving\n",
        "            self.lr += self.lr_alpha * abs(grad_lr)  # Increase learning rate\n",
        "            self.perturbation += self.lr_alpha * abs(grad_lr)  # Increase perturbation\n",
        "        else:  # Objective function is getting worse\n",
        "            self.lr -= self.lr_alpha * abs(grad_lr)  # Decrease learning rate\n",
        "            self.perturbation -= self.lr_alpha * abs(grad_lr)  # Decrease perturbation\n",
        "\n",
        "        # Ensure both learning rate and perturbation are positive\n",
        "        self.lr = max(0.001, self.lr)\n",
        "        self.perturbation = max(0.001, self.perturbation)\n",
        "\n",
        "    def step(self, gradient, obj_func_eval):\n",
        "        \"\"\"\n",
        "        Perform optimization step for both parameters, learning rate, and perturbation.\n",
        "        Use the objective function evaluation to dynamically adjust learning rate and perturbation.\n",
        "        \"\"\"\n",
        "        self._update_learning_rate_and_perturbation(gradient, obj_func_eval)\n",
        "        return super().step(gradient)  # Perform SPSA step for parameters\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reset the optimizer state (learning rates, perturbations, and gradient moving averages) for the next round.\n",
        "        \"\"\"\n",
        "        self.lr = initial_learning_rate\n",
        "        self.perturbation = initial_perturbation\n",
        "        self.gradient_moving_avg = 0  # Reset the moving average of the gradient\n",
        "        learning_rates.clear()  # Reset the learning rates history\n",
        "        perturbations.clear()  # Reset the perturbations history\n",
        "        objective_func_vals.clear()  # Clear the objective function history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "X46XXHW1s4tR"
      },
      "outputs": [],
      "source": [
        "# Create optimizer with learnable learning rate and perturbation\n",
        "spsa_optimizer = LearnableLRPerturbationSPSA(\n",
        "      maxiter=50, learning_rate=initial_learning_rate, perturbation=initial_perturbation, callback=spsa_callback, lr_alpha=0.01\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "-3Rhf0Ft7CI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e282c9d-2e2b-4843-9a99-53b1a4aba977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#======================================================\n",
        "# Initialize QNN model\n",
        "def initialize_model(num_features,initial_params):\n",
        "    feature_map = ZZFeatureMap(feature_dimension=num_features, reps=2)\n",
        "    ansatz = RealAmplitudes(num_qubits=num_features, reps=3)\n",
        "    qc = feature_map.compose(ansatz)\n",
        "\n",
        "    # Create optimizer with learnable learning rate and perturbation\n",
        "    spsa_optimizer = LearnableLRPerturbationSPSA(\n",
        "      maxiter=20, learning_rate=initial_learning_rate, perturbation=initial_perturbation, callback=spsa_callback, lr_alpha=0.01\n",
        ")\n",
        "    def parity(x):\n",
        "        return \"{:b}\".format(x).count(\"1\") % 2\n",
        "\n",
        "    sampler_qnn = SamplerQNN(\n",
        "        circuit=qc,\n",
        "        interpret=parity,\n",
        "        output_shape=2,\n",
        "        input_params=feature_map.parameters,\n",
        "        weight_params=ansatz.parameters\n",
        "    )\n",
        "\n",
        "\n",
        "    # Define the neural network classifier\n",
        "    qnn_classifier = NeuralNetworkClassifier(\n",
        "      neural_network=sampler_qnn,\n",
        "      optimizer=spsa_optimizer,\n",
        "      loss='squared_error',\n",
        "      initial_point=initial_params,  # Initialize with the starting parameters\n",
        ")\n",
        "\n",
        "\n",
        "    return qnn_classifier\n",
        "\n",
        "#=====================================================\n",
        "from google.colab import drive\n",
        "import csv\n",
        "# Step 1: Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Define the save path in Google Drive\n",
        "csv_file = '/content/drive/My Drive/DQFL_Genome__non-IID_31_03_2025v1.csv'\n",
        "\n",
        "# Step 3: Define headers for the CSV\n",
        "headers = [\"Federated Round\", \"Client Number\", \"Iteration\", \"Objective Function Value\",\n",
        "           \"Training Accuracy\", \"Test Accuracy\", \"Learning Rate\", \"Perturbation\"]\n",
        "\n",
        "# Open the CSV file and write headers if it's the first time writing to the file\n",
        "with open(csv_file, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(headers)\n",
        "\n",
        "# Example of saving results for each federated round and client\n",
        "def save_results(federated_round, client_id, iteration, obj_func_val, train_acc, test_acc, learning_rate, perturbation):\n",
        "    with open(csv_file, mode='a', newline='') as file:  # Open file in append mode\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([federated_round, client_id, iteration, obj_func_val, train_acc, test_acc, learning_rate, perturbation])\n",
        "#=====================================================\n",
        "# Federated learning loop per client\n",
        "def train_qnn_model(client_data, client_test_data, model=None, client_id=None, layer=None):\n",
        "\n",
        "    global learning_rates, perturbations, objective_func_vals\n",
        "    print(\"Client Data Structure:\")  # Add this line to print the structure\n",
        "    print(client_data)                # This line prints the actual data\n",
        "    print(type(client_data))           # This line prints the data type\n",
        "    #num_features = client_data[0][\"sequence\"].shape[0]\n",
        "\n",
        "    #initial_params = np.random.rand(RealAmplitudes(client_data.shape[1], reps=4).num_parameters)  # Initialize params\n",
        "    initial_params = np.random.rand(RealAmplitudes(len(client_data[0][\"sequence\"]), reps=3).num_parameters)\n",
        "\n",
        "    if model is None:\n",
        "        model = initialize_model(num_features, initial_params)\n",
        "\n",
        "    train_sequences = np.array([data_point[\"sequence\"] for data_point in client_data])\n",
        "\n",
        "    # Check if train_sequences has the correct shape\n",
        "    if train_sequences.shape[1] != num_features:  # Ensure num_features is 5\n",
        "        raise ValueError(f\"Input data shape incorrect. Expected {num_features} features, got {train_sequences.shape[1]}.\")\n",
        "\n",
        "    train_labels = np.array([data_point[\"label\"] for data_point in client_data])\n",
        "    test_sequences = np.array([data_point[\"sequence\"] for data_point in client_test_data])\n",
        "    test_labels = np.array([data_point[\"label\"] for data_point in client_test_data])\n",
        "\n",
        "    train_accuracies, test_accuracies, total_time = [], [], 0\n",
        "\n",
        "    train_accuracies = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    # Deep Unfolding with multiple iterations\n",
        "    # Continue training with learned weights and adjust learning rate based on performance and gradients.\n",
        "    total_time = 0\n",
        "    current_params = initial_params  # Start with the initial parameters\n",
        "\n",
        "    for i in range(num_deep_unfolding_iterations):\n",
        "        print(\"\\n\")\n",
        "        print(f\"Deep Unfolding Iteration {i+1}/{num_deep_unfolding_iterations}\")\n",
        "        start_time = time.time()\n",
        "        model.fit(train_sequences, train_labels)\n",
        "        end_time = time.time()\n",
        "        total_time += end_time - start_time\n",
        "\n",
        "        # After training, retrieve the updated parameters from the optimizer\n",
        "        current_params = model.weights\n",
        "        print(f\"Trained parameters after iteration {i+1}: {current_params}\")\n",
        "\n",
        "        # Store final weights and learning rate for next round\n",
        "        final_learning_rate = learning_rates[-1]\n",
        "        final_perturbation = perturbations[-1]\n",
        "\n",
        "        # Evaluate the model performance\n",
        "        train_accuracy = model.score(train_sequences, train_labels)\n",
        "        test_accuracy = model.score(test_sequences, test_labels)\n",
        "\n",
        "        # Store accuracies for future reference\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        test_accuracies.append(test_accuracy)\n",
        "\n",
        "\n",
        "        # Write the results to the CSV file\n",
        "        save_results(layer, client_id, i+1, objective_func_vals[-1], train_accuracy * 100, test_accuracy * 100, final_learning_rate, final_perturbation)\n",
        "\n",
        "        #with open(csv_file, mode='a', newline='') as file:\n",
        "          #writer = csv.writer(file)\n",
        "         #writer.writerow([i+1, objective_func_vals[-1], train_accuracy * 100, test_accuracy * 100, final_learning_rate, final_perturbation])\n",
        "\n",
        "        # Update the learning rate for the next iteration based on gradients from SPSA\n",
        "        spsa_optimizer.learning_rate = learning_rates[-1]\n",
        "        model.initial_point = current_params\n",
        "\n",
        "        # Log performance\n",
        "        print(f\"Iteration {i+1} - Learning Rate: {final_learning_rate:.6f}\")\n",
        "        print(f\"Iteration {i+1} - Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
        "        print(f\"Iteration {i+1} - Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "    return model, train_accuracy, train_accuracy, total_time\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step to empty the CSV file before starting a new run\n",
        "def clear_csv_file():\n",
        "    \"\"\"\n",
        "    Clears the CSV file by overwriting it with headers or leaving it blank.\n",
        "    \"\"\"\n",
        "    with open(csv_file, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        # Uncomment the next line to write headers for the new run\n",
        "        writer.writerow(headers)\n",
        "        # Leave it blank if you prefer not to include headers\n",
        "        # pass\n",
        "\n"
      ],
      "metadata": {
        "id": "AkLnHZoPTwB6"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "zpK0oXUHzPtm"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(model, test_sequences, test_labels):\n",
        "    \"\"\"\n",
        "    Evaluate the accuracy of the given model on the test dataset.\n",
        "\n",
        "    Parameters:\n",
        "        model: The trained model to evaluate.\n",
        "        num_features: The number of features in each data sample.\n",
        "        test_sequences: A list or array of test input data (features).\n",
        "        test_labels: A list or array of true labels corresponding to the test data.\n",
        "\n",
        "    Returns:\n",
        "        float: The accuracy of the model as a percentage.\n",
        "    \"\"\"\n",
        "    test_accuracy = model.score(test_sequences, test_labels)\n",
        "    return test_accuracy\n",
        "\n",
        "# Function to extract numerical values of parameters\n",
        "def extract_param_values(model):\n",
        "    #param_values = []\n",
        "    # Loop through each parameter in the circuit and get its bound value\n",
        "    # Retrieve the circuit from the neural network\n",
        "    circuit = model.neural_network.circuit\n",
        "\n",
        "    # Extract the parameter values bound to the circuit\n",
        "    # Use enumerate to get both index and parameter\n",
        "    param_values = {param: circuit.parameters[i] for i, param in enumerate(circuit.parameters)}\n",
        "    return param_values\n",
        "#def set_param_values(model, param_values):\n",
        "    # Retrieve the circuit from the neural network\n",
        "    #circuit = model.neural_network.circuit\n",
        "\n",
        "    # Use assign_parameters to update the parameter values\n",
        "    #circuit.assign_parameters(param_values, inplace=True)\n",
        "# Function to set numerical values of parameters back into the circuit\n",
        "def set_param_values(model, param_values):\n",
        "    # Assign the averaged parameter values back to the circuit\n",
        "    parameter_dict = {param: value for param, value in zip(model.neural_network.circuit.parameters, param_values)}\n",
        "    model.neural_network.circuit.assign_parameters(parameter_dict)\n",
        "\n",
        "\n",
        "# Manually average the numerical values of the parameters across clients\n",
        "def manual_average_weights(epoch_weights):\n",
        "    # Initialize a list to store the summed weights (initialize with zeros)\n",
        "    num_weights = len(epoch_weights[0])  # Number of weights in the model\n",
        "    num_clients = len(epoch_weights)  # Number of clients\n",
        "\n",
        "    # Initialize sum of weights to zero (assuming NumPy array or list of weights)\n",
        "    summed_weights = np.zeros(num_weights)\n",
        "\n",
        "    # Sum the weights from all clients\n",
        "    for client_weights in epoch_weights:\n",
        "        summed_weights += np.array(client_weights)\n",
        "\n",
        "    # Compute the average by dividing the summed weights by the number of clients\n",
        "    average_weights = summed_weights / num_clients\n",
        "\n",
        "    return average_weights\n",
        "\n",
        "def create_model_with_weights(weights):\n",
        "    initial_params = np.random.rand(RealAmplitudes(num_features, reps=3).num_parameters)\n",
        "    model = initialize_model(num_features,weights)\n",
        "    #set_param_values(model, weights)  # Assign global weights to the model\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "MuhZZtnnzmV5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Function to save accuracies to CSV\n",
        "def save_accuracies_to_csv(global_accuracies, clients_train_accuracies, clients_test_accuracies, filename='accuracies.csv'):\n",
        "    with open(filename, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "\n",
        "        # Write the header row\n",
        "        header = ['Epoch', 'Global Accuracy']\n",
        "        for i in range(len(clients_train_accuracies[0])):  # Assuming all clients have the same number of records\n",
        "            header.append(f'Client {i} Train Accuracy')\n",
        "            header.append(f'Client {i} Test Accuracy')\n",
        "        writer.writerow(header)\n",
        "\n",
        "        # Write the accuracy data for each epoch\n",
        "        for epoch in range(len(global_accuracies)):\n",
        "            row = [epoch, global_accuracies[epoch]]  # Start with epoch and global accuracy\n",
        "            for client_index in range(len(clients_train_accuracies[epoch])):\n",
        "                row.append(clients_train_accuracies[epoch][client_index])  # Add train accuracy for client\n",
        "                row.append(clients_test_accuracies[epoch][client_index])   # Add test accuracy for client\n",
        "            writer.writerow(row)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTt4DwZj7Is9"
      },
      "source": [
        "Federated Learning Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "BmYmJR4_7Hux",
        "outputId": "78b04d25-90f5-4d74-f336-55c7a0eff80c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'split_dataset_for_epochs' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c70ae1caea51>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_dataset_for_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_clients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_test_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'split_dataset_for_epochs' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "clients = split_dataset_for_epochs(num_clients, num_epochs, np_train_data, np_test_data, samples_per_epoch)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "def plot_label_distribution(clients):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for idx, client in enumerate(clients):\n",
        "        labels = [sample['label'] for epoch in client.data for sample in epoch]\n",
        "        label_counts = Counter(labels)\n",
        "        labels_sorted = sorted(label_counts.keys())\n",
        "        counts = [label_counts[label] for label in labels_sorted]\n",
        "\n",
        "        plt.bar(\n",
        "            [str(label) + f\"_C{idx}\" for label in labels_sorted],\n",
        "            counts,\n",
        "            label=f'Client {idx}'\n",
        "        )\n",
        "\n",
        "    plt.xlabel(\"Label per Client\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.title(\"Label Distribution per Client (Training Data)\")\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_label_distribution(clients)\n",
        "\n",
        "\n",
        "# Display information about the data assigned to each client, including epoch-wise splits\n",
        "for idx, client in enumerate(clients):\n",
        "    print(f\"Client {idx + 1}:\")\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"  Epoch {epoch + 1}: Train data samples: {len(client.data[epoch])}\")\n",
        "    print(f\"  Test data samples: {len(client.test_data)}\")\n",
        "\n",
        "# Display information about the data assigned to each client\n",
        "#for idx, client in enumerate(clients):\n",
        "    #print(f\"Client {idx + 1}:\")\n",
        "    #print(f\"  Train data samples: {len(client.data)}\")\n",
        "    #print(f\"  Test data samples: {len(client.test_data)}\")\n",
        "\n",
        "    # Accessing the number of features in a sequence\n",
        "    if client.data:\n",
        "        #num_features=client.data[0][0]['sequence'].shape[0]  # Access first data point of epoch 0\n",
        "        #num_features = client.data[0]['sequence'].shape[0]\n",
        "        print(f\"  Number of features in a sequence: {num_features}\")\n",
        "\n",
        "def reset_state():\n",
        "    # Reset the objective value, learning rate, and perturbation after each client\n",
        "    global objective_func_vals, learning_rates, perturbations\n",
        "    objective_func_vals = []  # Reset objective values\n",
        "    learning_rates = []  # Reset learning rates\n",
        "    perturbations = []  # Reset perturbations\n",
        "# Function to reset callback graph state after each round\n",
        "def reset_callback_graph():\n",
        "    global gradient_moving_avg, learning_rates, perturbations\n",
        "\n",
        "    # Reset the state variables to start fresh for the next round\n",
        "    gradient_moving_avg = np.zeros_like(gradient_moving_avg)  # Reset gradient moving average\n",
        "    learning_rates = [initial_learning_rate]  # Reset learning rates list to initial value\n",
        "    perturbations = [initial_perturbation]  # Reset perturbations list to initial value\n",
        "import csv\n",
        "\n",
        "# Path to store the best client's data\n",
        "best_client_csv_file = '/content/drive/My Drive/Best_Client_DQFL_Genome__non-IID_31_03_2025.csv'\n",
        "\n",
        "# Write headers to the best client CSV file\n",
        "best_headers = [\"Federated Round\", \"Client Number\"]\n",
        "\n",
        "with open(best_client_csv_file, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(best_headers)\n",
        "\n",
        "# Function to update the best client data\n",
        "def save_best_client_results(federated_round,best_client_index):\n",
        "    \"\"\"\n",
        "    Save the best client's data to a separate CSV file.\n",
        "    :param best_data: Dictionary containing the best client's data.\n",
        "    \"\"\"\n",
        "    with open(best_client_csv_file, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([federated_round,\n",
        "           best_client_index\n",
        "\n",
        "        ])\n",
        "# Clear the CSV file for a new run\n",
        "clear_csv_file()\n",
        "\n",
        "# Wrap the epoch loop with tqdm\n",
        "for epoch in tqdm(range(num_federated_layers), desc=\"Training Progress\"):\n",
        "    global_model_weights[epoch] = []\n",
        "    epoch_train_accuracies, epoch_test_accuracies = [], []\n",
        "    best_client_index = -1\n",
        "    best_client_accuracy = -1\n",
        "    best_client_model = None\n",
        "    print(\"\\n\")\n",
        "    print(f\"Fed_Epoch: {epoch}\")\n",
        "\n",
        "    for index, client in enumerate(clients):\n",
        "        print(\"\\n\")\n",
        "        print(f\"Fed_Epoch {epoch}, Client {index + 1}:\")\n",
        "        reset_state()\n",
        "\n",
        "        try:\n",
        "            # Ensure you're using the correct index for data\n",
        "            current_data = client.data[epoch]  # This assumes data is structured in epochs\n",
        "            print(f\"Training data for epoch {epoch}: {len(current_data)}\")\n",
        "        except IndexError:\n",
        "            print(f\"No data available for epoch {epoch} for Client {index + 1}\")\n",
        "            continue  # Skip this client for the current epoch\n",
        "\n",
        "        model, train_score, test_score, train_time = train_qnn_model(\n",
        "            client.data[epoch],\n",
        "            client.test_data,\n",
        "            client_id=index,\n",
        "            layer=epoch,\n",
        "        )\n",
        "\n",
        "        epoch_train_accuracies.append(train_score)\n",
        "        epoch_test_accuracies.append(test_score)\n",
        "\n",
        "        # Check if this client has the best accuracy so far\n",
        "        if test_score > best_client_accuracy:\n",
        "            best_client_accuracy = test_score\n",
        "            best_client_index = index\n",
        "            best_client_model = model  # Directly store the best client's model\n",
        "\n",
        "    save_best_client_results(epoch,best_client_index)  # Save to best client CSV\n",
        "    print(f\"Best client for epoch {epoch} is Client {best_client_index + 1} with test accuracy {best_client_accuracy:.2f}\")\n",
        "\n",
        "    # Treat the best client's model as the global model for the next round\n",
        "    global_model = best_client_model\n",
        "\n",
        "    # Update all clients with the global model\n",
        "    for index, client in enumerate(clients):\n",
        "        client.primary_model = global_model\n",
        "\n",
        "    # Evaluate the global model on the new test data\n",
        "    global_accuracy = get_accuracy(global_model, test_sequences, test_labels)\n",
        "    global_model_accuracy.append(global_accuracy)\n",
        "\n",
        "    clients_train_accuracies.append(epoch_train_accuracies)\n",
        "    clients_test_accuracies.append(epoch_test_accuracies)\n",
        "\n",
        "    print(f\"Global Model Accuracy in Epoch {epoch}: {global_accuracy:.2f}\")\n",
        "    print(\"----------------------------------------------------------\")\n",
        "\n",
        "\n",
        "    # Save results for the current iteration of the client in the federated round\n",
        "    from google.colab import drive\n",
        "\n",
        "    # Step 1: Mount Google Drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Step 2: Define the save path in Google Drive\n",
        "    save_path = '/content/drive/MyDrive/DQFL_Genome__non-IID_Global_31_03_2025.csv'\n",
        "\n",
        "\n",
        "    # Save accuracies to CSV after each epoch (or at the end of all epochs)\n",
        "    save_accuracies_to_csv(global_model_accuracy, clients_train_accuracies, clients_test_accuracies, filename=save_path)\n",
        "    # After each round, reset callback state to prepare for the next round\n",
        "    reset_callback_graph()\n",
        "    print(f\"File saved to {save_path}\")\n",
        "\n",
        "#print(\"Accuracy data saved to\", csv_file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Zs_rlJT5XJv"
      },
      "source": [
        "Split data as iid and non-iid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pgm1g3VHfXC"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#Introduce custome cross entropy function\n",
        "import numpy as np\n",
        "\n",
        "# Callback for updating learning rate dynamically with deep unfolding principles\n",
        "def deep_unfolding_learning_rate_adjustment(obj_func_eval, gradients=None, client_id=None, layer=None):\n",
        "    global gradient_moving_avg, learning_rates, perturbations,meta_alpha, meta_epsilon, momentum\n",
        "\n",
        "    # Initialize moving average for gradients\n",
        "    if gradients is not None:\n",
        "        if not isinstance(gradient_moving_avg, np.ndarray) or gradient_moving_avg.size == 0:\n",
        "            gradient_moving_avg = gradients\n",
        "        else:\n",
        "            # Update moving average of gradients (Momentum)\n",
        "            gradient_moving_avg = momentum * gradient_moving_avg + (1 - momentum) * gradients\n",
        "        # Calculate the average gradient\n",
        "        avg_gradient = np.mean(gradient_moving_avg)\n",
        "\n",
        "        # Normalize delta_lr by L2 norm of the gradient\n",
        "        norm_gradient = np.linalg.norm(gradients)\n",
        "\n",
        "        '''\n",
        "        # Normalization to prevent instability\n",
        "        norm_gradient = gradients / (np.linalg.norm(gradients) + 1e-8)\n",
        "        avg_gradient = np.mean(norm_gradient)\n",
        "        '''\n",
        "        # Trainable scaling for deep unfolding (meta-parameter)\n",
        "        meta_alpha = 0.01  # This can be learned via a hypernetwork or meta-learning\n",
        "        meta_epsilon = 1e-6  # Small offset to ensure numerical stability\n",
        "        # Gradually adjust learning rate based on gradient signs and magnitude\n",
        "        # This formula gradually adds or subtracts from the learning rate instead of multiplication\n",
        "        delta_lr = meta_alpha * np.sign(avg_gradient) * np.sqrt(np.abs(avg_gradient) + meta_epsilon) / (norm_gradient + 1e-6)\n",
        "\n",
        "        #delta_lr = meta_alpha * np.sign(avg_gradient) * np.sqrt(np.abs(avg_gradient) + meta_epsilon)\n",
        "    # Apply gradual adjustment (either addition or subtraction based on the direction of the gradient)\n",
        "        if avg_gradient > 0:\n",
        "            delta_lr = delta_lr - 0.001  # Decrease if gradient is positive (potential overfitting)\n",
        "        else:\n",
        "            delta_lr = delta_lr + 0.001  # Increase if gradient is negative (potential underfitting)\n",
        "    else:\n",
        "        delta_lr = 0\n",
        "\n",
        "    # Compute new learning rate with clamping for stability\n",
        "    new_lr = max(0.001, min(5.0, learning_rates[-1] + delta_lr)) if learning_rates else initial_learning_rate\n",
        "\n",
        "    # Update per-client, per-layer information if federated\n",
        "    if client_id is not None and layer is not None:\n",
        "        if client_id not in client_data:\n",
        "            client_data[client_id] = {'federated_layers': {}}\n",
        "        if layer not in client_data[client_id]['federated_layers']:\n",
        "            client_data[client_id]['federated_layers'][layer] = {'objective_values': [], 'learning_rates': []}\n",
        "\n",
        "        # Store loss and learning rate for the specific client and layer\n",
        "        client_data[client_id]['federated_layers'][layer]['objective_values'].append(obj_func_eval)\n",
        "        client_data[client_id]['federated_layers'][layer]['learning_rates'].append(new_lr)\n",
        "\n",
        "    # Store global metrics\n",
        "    objective_func_vals.append(obj_func_eval)  # Store the loss value globally\n",
        "    learning_rates.append(new_lr)  # Append the new learning rate to the history\n",
        "\n",
        "    # Update meta-parameters (meta_alpha and meta_epsilon) using gradient descent\n",
        "    #meta_gradients = compute_meta_gradients(gradients, avg_gradient, delta_lr)\n",
        "    #meta_alpha -= meta_learning_rate * meta_gradients['alpha']\n",
        "    #meta_epsilon -= meta_learning_rate * meta_gradients['epsilon']\n",
        "\n",
        "    # Debug output for analysis\n",
        "    # print(f\"Objective Function Value: {obj_func_eval:.6f}, New Learning Rate: {new_lr:.6f}\")\n",
        "\n",
        "    return new_lr\n",
        "\n",
        "\n",
        "def callback_graph(weights, loss):\n",
        "    \"\"\"Callback to log and synchronize loss during training.\"\"\"\n",
        "    #print(f\"Loss = {loss}\")\n",
        "    if len(objective_func_vals) == 0 or loss != objective_func_vals[-1]:\n",
        "        objective_func_vals.append(loss)\n",
        "\n",
        "spsa_optimizer = SPSA(maxiter=50, learning_rate=0.01, perturbation = 0.15, callback=lambda nfev, params, obj_func_eval, stepsize, accept: deep_unfolding_learning_rate_adjustment(obj_func_eval, stepsize))\n",
        "\n",
        "\n",
        "\n",
        "# Define the CSV file path\n",
        "csv_file_path = 'federated_learning_accuracy.csv'\n",
        "\n",
        "# Open the CSV file in write mode and add headers (if starting fresh)\n",
        "with open(csv_file_path, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    # Write the header\n",
        "    writer.writerow(['Epoch', 'Global Accuracy'] + [f'Client {i+1} Final Accuracy' for i in range(num_clients)])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPn8nonXisKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e440af7-4865-4dea-e33e-e99f0876a4db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-124de6133a8b>:17: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
            "  qnn = SamplerQNN(\n",
            "<ipython-input-15-124de6133a8b>:33: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
            "  qnn = SamplerQNN(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.66519637, 0.33480363]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "from qiskit import QuantumCircuit\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit_machine_learning.circuit.library import QNNCircuit\n",
        "\n",
        "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
        "\n",
        "num_qubits = 2\n",
        "\n",
        "def parity(x):\n",
        "    return f\"{bin(x)}\".count(\"1\") % 2\n",
        "\n",
        "# Using the QNNCircuit:\n",
        "# Create a parameterized 2 qubit circuit composed of the default ZZFeatureMap feature map\n",
        "# and RealAmplitudes ansatz.\n",
        "qnn_qc = QNNCircuit(num_qubits)\n",
        "\n",
        "qnn = SamplerQNN(\n",
        "    circuit=qnn_qc,\n",
        "    interpret=parity,\n",
        "    output_shape=2\n",
        ")\n",
        "\n",
        "qnn.forward(input_data=[1, 2], weights=[1, 2, 3, 4, 5, 6, 7, 8])\n",
        "\n",
        "# Explicitly specifying the ansatz and feature map:\n",
        "feature_map = ZZFeatureMap(feature_dimension=num_qubits)\n",
        "ansatz = RealAmplitudes(num_qubits=num_qubits)\n",
        "\n",
        "qc = QuantumCircuit(num_qubits)\n",
        "qc.compose(feature_map, inplace=True)\n",
        "qc.compose(ansatz, inplace=True)\n",
        "\n",
        "qnn = SamplerQNN(\n",
        "    circuit=qc,\n",
        "    input_params=feature_map.parameters,\n",
        "    weight_params=ansatz.parameters,\n",
        "    interpret=parity,\n",
        "    output_shape=2\n",
        ")\n",
        "\n",
        "qnn.forward(input_data=[1, 2], weights=[1, 2, 3, 4, 5, 6, 7, 8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HV9T-8JBzwMo"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "filename = 'accuracies.csv'\n",
        "data = pd.read_csv(filename)\n",
        "\n",
        "# Extract the relevant columns for plotting\n",
        "epochs = data['Epoch']\n",
        "global_accuracy = data['Global Accuracy']\n",
        "client_train_accuracies = data.filter(like='Train Accuracy').values\n",
        "client_test_accuracies = data.filter(like='Test Accuracy').values\n",
        "\n",
        "# Plot Global Accuracy over Epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, global_accuracy, label='Global Accuracy', color='blue', marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Global Accuracy')\n",
        "plt.title('Global Accuracy Over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot Train Accuracies for all clients over Epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "for i in range(client_train_accuracies.shape[1]):\n",
        "    plt.plot(epochs, client_train_accuracies[:, i], label=f'Client {i} Train Accuracy', marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Train Accuracy')\n",
        "plt.title('Train Accuracies for All Clients Over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot Test Accuracies for all clients over Epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "for i in range(client_test_accuracies.shape[1]):\n",
        "    plt.plot(epochs, client_test_accuracies[:, i], label=f'Client {i} Test Accuracy', marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Test Accuracy')\n",
        "plt.title('Test Accuracies for All Clients Over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a_q7UqBTcju"
      },
      "source": [
        "new ways to average"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1wzVu0QDWaGORXG5Ye_xJj4xO8ALG8Hud",
      "authorship_tag": "ABX9TyN/zm/Ch6PEj1hvqxrfQxZF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}