{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shanikairoshi/DUQFL/blob/main/QFL_best_avg_Genome_improvedMaxiter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dhs01V-773BK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quantum Federated Learning with Weighted Aggregation\n",
        "This notebook demonstrates how to implement different weighting mechanisms for federated learning.\n",
        "We'll experiment with fixed weighting, performance-based weighting, and dynamic scaling to aggregate\n",
        "model weights across\n"
      ],
      "metadata": {
        "id": "kNPWFyLv1jPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%capture\n",
        "!pip install genomic-benchmarks\n",
        "!pip install qiskit qiskit_machine_learning qiskit_algorithms\n",
        "!pip install qiskit-aer\n",
        "%%capture\n",
        "!pip install qiskit\n",
        "!pip install qiskit_machine_learning"
      ],
      "metadata": {
        "id": "WUPDEH5t7_Ez"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from genomic_benchmarks.dataset_getters.pytorch_datasets import DemoHumanOrWorm\n",
        "\n",
        "test_set = DemoHumanOrWorm(split='test', version=0)\n",
        "train_set = DemoHumanOrWorm(split='train', version=0)\n",
        "\n",
        "data_set = train_set\n",
        "# data_set = train_set + test_set\n",
        "len(data_set)\n",
        "\n",
        "from genomic_benchmarks.dataset_getters.pytorch_datasets import DemoHumanOrWorm\n",
        "\n",
        "test_set = DemoHumanOrWorm(split='test', version=0)\n",
        "train_set = DemoHumanOrWorm(split='train', version=0)\n",
        "\n",
        "data_set = train_set\n",
        "# data_set = train_set + test_set\n",
        "len(data_set)\n",
        "\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "word_size = 40\n",
        "word_combinations = defaultdict(int)\n",
        "iteration = 1\n",
        "for text, _ in data_set:\n",
        "    for i in range(len(text)):\n",
        "        word = text[i:i+word_size]\n",
        "        if word_combinations.get(word) is None:\n",
        "          word_combinations[word] = iteration\n",
        "          iteration += 1\n",
        "\n",
        "\n",
        "\n",
        "print(\"First sample int the data_set variable: \")\n",
        "print(data_set[0])\n",
        "\n",
        "print(\"\\nFirst 5 samples in the word_combinations dict.\")\n",
        "for key, value in list(word_combinations.items())[:5]:\n",
        "    print(key, value)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "# Preprocess the training set\n",
        "np_data_set = []\n",
        "for i in range(len(data_set)):\n",
        "    sequence, label = data_set[i]\n",
        "    sequence = sequence.strip()  # Remove any leading/trailing whitespace\n",
        "    words = [sequence[i:i + word_size] for i in range(0, len(sequence), word_size)]  # Split the sequence into 4-letter words\n",
        "    int_sequence = np.array([word_combinations[word] for word in words])\n",
        "    data_point = {'sequence': int_sequence, 'label': label}\n",
        "    np_data_set.append(data_point)\n",
        "\n",
        "\n",
        "print(\"First 5 samples of encoded data:\")\n",
        "np_data_set[:5]\n",
        "\n",
        "\n",
        "np.random.shuffle(np_data_set)\n",
        "print(\"First 5 samples of encoded shuffled data:\")\n",
        "np_data_set[:5]\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "sequences = np.array([item['sequence'] for item in np_data_set])\n",
        "sequences = np.vstack(sequences)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "sequences_scaled = scaler.fit_transform(sequences)\n",
        "\n",
        "for i, item in enumerate(np_data_set):\n",
        "    item['sequence'] = sequences_scaled[i]\n",
        "\n",
        "print(\"First 5 samples of scaled encoded shuffled data:\")\n",
        "np_data_set[:5]\n",
        "\n",
        "\n",
        "np_train_data = np_data_set[:5000] #change data from 15000 to 5000\n",
        "np_test_data = np_data_set[-5000:]\n",
        "\n",
        "print(f\"Length of np_train_data: {len(np_train_data)}\")\n",
        "print(f\"Length of np_test_data: {len(np_test_data)}\")\n",
        "\n",
        "test_sequences = [data_point[\"sequence\"] for data_point in np_test_data]\n",
        "test_labels = [data_point[\"label\"] for data_point in np_test_data]\n",
        "test_sequences = np.array(test_sequences)\n",
        "test_labels = np.array(test_labels)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aakuRe028GMO",
        "outputId": "f7a714f1-0121-4e59-8a30-dd33268f258e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First sample int the data_set variable: \n",
            "('TGTCACCTTGCAGTCCCCCTTTGATTTTTTTCTTGTTTTTTTCAGATTGATCCTTTTTCTGATAGTATACCTTCCCACTGCTGAGCTCTAATTCATTAAAAGAAAAAATGTGGGCCACATTTCTGCAGCAGCCCCTTTCCTTAGATTGTAAATTCTAGGGGCAGACTTAGCTGAGGAAGGGAGGTGAATGCACAGCGGGC', 0)\n",
            "\n",
            "First 5 samples in the word_combinations dict.\n",
            "TGTCACCTTGCAGTCCCCCTTTGATTTTTTTCTTGTTTTT 1\n",
            "GTCACCTTGCAGTCCCCCTTTGATTTTTTTCTTGTTTTTT 2\n",
            "TCACCTTGCAGTCCCCCTTTGATTTTTTTCTTGTTTTTTT 3\n",
            "CACCTTGCAGTCCCCCTTTGATTTTTTTCTTGTTTTTTTC 4\n",
            "ACCTTGCAGTCCCCCTTTGATTTTTTTCTTGTTTTTTTCA 5\n",
            "First 5 samples of encoded data:\n",
            "First 5 samples of encoded shuffled data:\n",
            "First 5 samples of scaled encoded shuffled data:\n",
            "Length of np_train_data: 5000\n",
            "Length of np_test_data: 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset_for_epochs(num_clients, num_epochs, train_data, test_data, samples_per_epoch):\n",
        "    \"\"\"\n",
        "    Split the dataset across multiple epochs and clients.\n",
        "\n",
        "    Args:\n",
        "        num_clients (int): Number of clients.\n",
        "        num_epochs (int): Number of epochs.\n",
        "        train_data (list): List of training data points.\n",
        "        test_data (list): List of test data points.\n",
        "        samples_per_epoch (int): Number of samples per epoch.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of Client objects with assigned data for each epoch.\n",
        "    \"\"\"\n",
        "    clients = []\n",
        "\n",
        "    # Split the training data across epochs and clients\n",
        "    train_samples_per_client = len(train_data) // num_clients\n",
        "\n",
        "    for i in range(num_clients):\n",
        "        client_data_for_epochs = []\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            start_idx = (i * num_epochs * samples_per_epoch) + (epoch * samples_per_epoch)\n",
        "            end_idx = (i * num_epochs * samples_per_epoch) + ((epoch + 1) * samples_per_epoch)\n",
        "            client_data_for_epochs.append(train_data[start_idx:end_idx])\n",
        "\n",
        "        # Assign test data to each client\n",
        "        test_samples_per_client = len(test_data) // num_clients\n",
        "        test_start_idx = i * test_samples_per_client\n",
        "        test_end_idx = (i + 1) * test_samples_per_client\n",
        "        client_test_data = test_data[test_start_idx:test_end_idx]\n",
        "\n",
        "        # Create a Client instance with epoch-specific data\n",
        "        clients.append(Client(client_data_for_epochs, client_test_data))\n",
        "\n",
        "    return clients\n"
      ],
      "metadata": {
        "id": "IhL53MnwU7nP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
        "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit.primitives import BackendSampler\n",
        "from qiskit_algorithms.optimizers import SPSA\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit_algorithms.optimizers import COBYLA\n",
        "from qiskit_machine_learning.algorithms.classifiers import VQC\n",
        "from qiskit.primitives import BackendSampler\n",
        "from functools import partial\n",
        "from qiskit_aer import Aer\n",
        "\n",
        "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
        "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit.primitives import BackendSampler\n",
        "from qiskit_algorithms.optimizers import SPSA\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "num_clients = 5\n",
        "num_epochs = 10\n",
        "max_train_iterations = 100\n",
        "samples_per_epoch=100\n",
        "backend = Aer.get_backend('aer_simulator')\n",
        "\n",
        "class Client:\n",
        "   def __init__(self, data, test_data):  # Add test_data to __init__\n",
        "        self.data = data\n",
        "        self.test_data = test_data  # Store test_data as an attribute\n",
        "        self.models = []\n",
        "        self.train_scores = []\n",
        "        self.test_scores = []\n",
        "        self.primary_model = None\n",
        "\n",
        "def split_dataset_for_epochs(num_clients, num_epochs, train_data, test_data, samples_per_epoch, data_proportions):\n",
        "    \"\"\"\n",
        "    Split the dataset across multiple epochs and clients based on data proportions.\n",
        "\n",
        "    Args:\n",
        "        num_clients (int): Number of clients.\n",
        "        num_epochs (int): Number of epochs.\n",
        "        train_data (list): List of training data points.\n",
        "        test_data (list): List of test data points.\n",
        "        samples_per_epoch (int): Number of samples per epoch.\n",
        "        data_proportions (list): Proportion of data assigned to each client (length must equal num_clients).\n",
        "\n",
        "    Returns:\n",
        "        list: A list of Client objects with assigned data for each epoch.\n",
        "    \"\"\"\n",
        "    assert len(data_proportions) == num_clients, \"Length of data_proportions must match num_clients.\"\n",
        "    assert abs(sum(data_proportions) - 1.0) < 1e-6, \"Data proportions must sum to 1.\"\n",
        "\n",
        "    clients = []\n",
        "    total_train_samples = len(train_data)\n",
        "\n",
        "    # Compute the number of training samples for each client based on proportions\n",
        "    train_samples_per_client = [int(total_train_samples * prop) for prop in data_proportions]\n",
        "\n",
        "    train_start_idx = 0\n",
        "\n",
        "    for i in range(num_clients):\n",
        "        client_data_for_epochs = []\n",
        "\n",
        "        # Get the number of samples for this client\n",
        "        client_train_samples = train_samples_per_client[i]\n",
        "        train_end_idx = train_start_idx + client_train_samples\n",
        "\n",
        "        # Split client's training data across epochs\n",
        "        for epoch in range(num_epochs):\n",
        "            start_idx = train_start_idx + (epoch * samples_per_epoch)\n",
        "            end_idx = min(train_start_idx + ((epoch + 1) * samples_per_epoch), train_end_idx)\n",
        "            client_data_for_epochs.append(train_data[start_idx:end_idx])\n",
        "\n",
        "        train_start_idx = train_end_idx  # Update for the next client\n",
        "\n",
        "        # Split test data equally among clients\n",
        "        test_samples_per_client = len(test_data) // num_clients\n",
        "        test_start_idx = i * test_samples_per_client\n",
        "        test_end_idx = (i + 1) * test_samples_per_client\n",
        "        client_test_data = test_data[test_start_idx:test_end_idx]\n",
        "\n",
        "        # Create a Client instance with epoch-specific data\n",
        "        clients.append(Client(client_data_for_epochs, client_test_data))\n",
        "\n",
        "    return clients\n",
        "\n",
        "# Define proportions for each client\n",
        "data_proportions = [0.1, 0.3, 0.2,0.2,0.2]  # Must sum to 1\n",
        "\n",
        "# Split the dataset\n",
        "clients = split_dataset_for_epochs(\n",
        "    num_clients=num_clients,\n",
        "    num_epochs=num_epochs,\n",
        "    train_data=np_train_data,\n",
        "    test_data=np_test_data,\n",
        "    samples_per_epoch=samples_per_epoch,\n",
        "    data_proportions=data_proportions\n",
        ")\n"
      ],
      "metadata": {
        "id": "7tInJSWe8OU3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each client's allocated training data is divided into num_epochs subsets.\n",
        "Each epoch is designed to contain a fixed number of samples (samples_per_epoch), e.g., 100 samples in your example.\n",
        "As a result:\n",
        "Client 0 has 5000 / 100 = 50 epochs in total.\n",
        "Client 1 has 3000 / 100 = 30 epochs in total.\n",
        "Client 2 has 2000 / 100 = 20 epochs in total."
      ],
      "metadata": {
        "id": "2C0ub1BFIVNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify test data distribution across clients\n",
        "for index, client in enumerate(clients):\n",
        "    print(f\"Client {index} Test Data Length: {len(client.test_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJpAjUWiCw-2",
        "outputId": "7883108b-e001-4a5f-da23-c47586d1827f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 0 Test Data Length: 1666\n",
            "Client 1 Test Data Length: 1666\n",
            "Client 2 Test Data Length: 1666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_samples_per_client = len(np_test_data) // num_clients\n",
        "remainder = len(np_test_data) % num_clients\n"
      ],
      "metadata": {
        "id": "q4hkBlYGDjlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index, client in enumerate(clients):\n",
        "    labels = [data_point['label'] for data_point in client.test_data]\n",
        "    print(f\"Client {index} Label Distribution: {np.bincount(labels)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYTfoocvDlWJ",
        "outputId": "cd54836a-b7c3-4bbb-d190-3e8996c5fdc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 0 Label Distribution: [848 818]\n",
            "Client 1 Label Distribution: [816 850]\n",
            "Client 2 Label Distribution: [849 817]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for index, client in enumerate(clients):\n",
        "    labels = [data_point['label'] for data_point in client.test_data]\n",
        "    print(f\"Client {index} Label Distribution: {np.bincount(labels)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCDWmmbGDnZB",
        "outputId": "76ef1738-5fa7-4f7b-a436-a825d5a82ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 0 Label Distribution: [848 818]\n",
            "Client 1 Label Distribution: [816 850]\n",
            "Client 2 Label Distribution: [849 817]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if len(client.test_data) == 0:\n",
        "    print(f\"Warning: Client {index} has no test data.\")\n"
      ],
      "metadata": {
        "id": "k0qrWXQrDpwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check training data length for each client\n",
        "for index, client in enumerate(clients):\n",
        "    train_data_lengths = [len(epoch_data) for epoch_data in client.data]\n",
        "    total_train_samples = sum(train_data_lengths)\n",
        "    print(f\"Client {index}: Total Training Samples: {total_train_samples}, Epoch Samples: {train_data_lengths}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06YMAL8sD_RO",
        "outputId": "e36c2a77-ee70-4211-8bd4-da61acb5e9ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 0: Total Training Samples: 5000, Epoch Samples: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]\n",
            "Client 1: Total Training Samples: 4500, Epoch Samples: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 0, 0, 0, 0, 0]\n",
            "Client 2: Total Training Samples: 3000, Epoch Samples: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Proportional Weighting"
      ],
      "metadata": {
        "id": "k08xuu0_xKj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "YZXVjtSWxHep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concept: Use each client model's performance (e.g., test accuracy) to determine the weight factor. Higher-performing models contribute more.\n",
        "Normalization: Normalize accuracies so their sum equals 1.\n",
        "𝑤\n",
        "𝑖\n",
        "=\n",
        "accuracy\n",
        "𝑖\n",
        "∑\n",
        "𝑗\n",
        "=\n",
        "1\n",
        "𝑁\n",
        "accuracy\n",
        "𝑗\n",
        "w\n",
        "i\n",
        "​\n",
        " =\n",
        "∑\n",
        "j=1\n",
        "N\n",
        "​\n",
        " accuracy\n",
        "j\n",
        "​\n",
        "\n",
        "accuracy\n",
        "i\n",
        "​\n",
        "\n",
        "​\n"
      ],
      "metadata": {
        "id": "JAGQTj2040Oc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9tkgdzAZyd7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hybrid weighting\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "Z4z-xQWU3Dl7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entropy-Based Weighting\n",
        "In this method, we calculate the entropy of predictions for each model to measure uncertainty.\n",
        "- **Lower entropy** implies higher confidence in predictions, and such models are given higher weight.\n",
        "- **Higher entropy** implies lower confidence, resulting in lower weights.\n",
        "\n",
        "The entropy for a prediction probability distribution is computed as:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I5aVY82z1Zht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fairness-Based Weighting**\n",
        "\n",
        "***Concept: ***Ensure fairness by assigning weights inversely proportional to how much a client’s data overlaps with the global data distribution. Diverse clients receive higher weights.\n",
        "\n",
        "***Technique:*** Use metrics like cosine similarity or Kullback-Leibler divergence to compare each client’s data distribution with the global distribution."
      ],
      "metadata": {
        "id": "xJHNuMwG0piW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assign equal weights to all clients when there is no clear reason to favor any specific client.\n",
        "𝑤\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝑁\n",
        "w\n",
        "i\n",
        "​\n",
        " =\n",
        "N\n",
        "1\n",
        "​\n",
        "\n"
      ],
      "metadata": {
        "id": "R_dYkmWU0bz0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cDzTxlEftmd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def aggregate_weights(client_weights, weight_factors):\n",
        "    num_clients = len(client_weights)\n",
        "    aggregated_weights = [np.zeros_like(client_weights[0]) for _ in range(len(client_weights[0]))]\n",
        "\n",
        "    for client_index, weights in enumerate(client_weights):\n",
        "        for layer_index, layer_weights in enumerate(weights):\n",
        "            aggregated_weights[layer_index] += weight_factors[client_index] * np.array(layer_weights)\n",
        "\n",
        "    return aggregated_weights\n"
      ],
      "metadata": {
        "id": "jyuWK_gKt3uH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
        "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit.primitives import BackendSampler\n",
        "from qiskit_algorithms.optimizers import SPSA\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Callback function to visualize training progress\n",
        "objective_func_vals = []\n",
        "def callback_graph(weights, obj_func_eval):\n",
        "    clear_output(wait=True)\n",
        "    objective_func_vals.append(obj_func_eval)\n",
        "    plt.title(\"Objective function value against iteration\")\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Objective function value\")\n",
        "    plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
        "    plt.show()\n",
        "\n",
        "# Function to create the QNN model\n",
        "def initialize_qnn_model(data_train):\n",
        "    num_features = data_train[0][\"sequence\"].shape[0]\n",
        "    # Define the quantum feature map and ansatz\n",
        "    feature_map = ZZFeatureMap(feature_dimension=num_features, reps=2)\n",
        "    ansatz = RealAmplitudes(num_qubits=num_features, reps=3)\n",
        "\n",
        "    # Construct the quantum neural network using a sampler\n",
        "\n",
        "    qc = feature_map.compose(ansatz)  # Build the QNN circuit\n",
        "    print(f\"Number of features (input dimension): {num_features}\")\n",
        "    print(f\"Number of circuit parameters: {qc.num_parameters}\")\n",
        "\n",
        "    # Use parity as the interpretation function\n",
        "    def parity(x):\n",
        "        return \"{:b}\".format(x).count(\"1\") % 2  # Binary classification\n",
        "\n",
        "    # Explicitly define input_params and weight_params\n",
        "    input_params = feature_map.parameters  # Parameters for the feature map (inputs)\n",
        "    weight_params = ansatz.parameters      # Parameters for the ansatz (weights)\n",
        "    #print(f\"Input Parameters: {input_params}\")\n",
        "    #print(f\"Weight Parameters: {weight_params}\")\n",
        "\n",
        "    sampler_qnn = SamplerQNN(\n",
        "        circuit=qc,\n",
        "        interpret=parity,\n",
        "        output_shape=2,  # Output dimension for binary classification\n",
        "        input_params=input_params,       # Pass input parameters\n",
        "        weight_params=weight_params     # Pass weight parameters\n",
        "    )\n",
        "\n",
        "    # Define a classifier using the QNN\n",
        "    qnn_classifier = NeuralNetworkClassifier(\n",
        "        neural_network=sampler_qnn,\n",
        "        optimizer=SPSA(maxiter=50,learning_rate=0.01, perturbation = 0.15),  # Example with SPSA optimizer\n",
        "        #callback=callback_graph\n",
        "    )\n",
        "\n",
        "    return qnn_classifier\n"
      ],
      "metadata": {
        "id": "1y15tIMv8nso"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to initialize a new QNN model (same architecture as clients' models)\n",
        "def create_modal(num_features):\n",
        "    # Create the same quantum neural network (QNN) architecture as clients\n",
        "    feature_map = ZZFeatureMap(feature_dimension=num_features, reps=2)\n",
        "    ansatz = RealAmplitudes(num_qubits=num_features, reps=3)\n",
        "\n",
        "    # Combine the feature map and ansatz into a single quantum circuit\n",
        "    qc = feature_map.compose(ansatz)\n",
        "\n",
        "    # Use parity as the interpretation function\n",
        "    def parity(x):\n",
        "        return \"{:b}\".format(x).count(\"1\") % 2  # Binary classification\n",
        "\n",
        "    # Explicitly define input_params and weight_params\n",
        "    input_params = feature_map.parameters  # Input parameters (for encoding)\n",
        "    weight_params = ansatz.parameters      # Trainable parameters (for optimization)\n",
        "\n",
        "    # Define the QNN model using a sampler\n",
        "    sampler_qnn = SamplerQNN(\n",
        "        circuit=qc,\n",
        "        interpret=parity,\n",
        "        output_shape=2,  # Binary classification\n",
        "        input_params=input_params,\n",
        "        weight_params=weight_params\n",
        "    )\n",
        "\n",
        "    # Create a classifier using the neural network\n",
        "    qnn_classifier = NeuralNetworkClassifier(\n",
        "        neural_network=sampler_qnn,\n",
        "        optimizer=SPSA(maxiter=50,learning_rate=0.01, perturbation = 0.15)  # Use SPSA optimizer\n",
        "    )\n",
        "\n",
        "    return qnn_classifier\n",
        "\n",
        "# Function to create a global model with averaged weights\n",
        "def create_model_with_weights(average_weights, num_features):\n",
        "    # Initialize a new QNN model with the same architecture\n",
        "    model = create_modal(num_features)\n",
        "    # Assign the averaged weights to the model's trainable parameters (ansatz weights)\n",
        "    weight_params = model.neural_network.weight_params  # Get the trainable parameters\n",
        "\n",
        "    # Check if the lengths match, and truncate if necessary\n",
        "    num_weights = min(len(average_weights), len(weight_params))\n",
        "\n",
        "    # Create a dictionary mapping parameters to averaged weights\n",
        "    param_dict = {param: average_weights[i] for i, param in enumerate(weight_params[:num_weights])}\n",
        "\n",
        "\n",
        "    # Assign the averaged weights to the circuit parameters\n",
        "    model.neural_network.circuit.assign_parameters(param_dict)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "RxKL1IqC7KNc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step to empty the CSV file before starting a new run\n",
        "def clear_csv_file():\n",
        "    \"\"\"\n",
        "    Clears the CSV file by overwriting it with headers or leaving it blank.\n",
        "    \"\"\"\n",
        "    with open(csv_file, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        # Uncomment the next line to write headers for the new run\n",
        "        writer.writerow(headers)\n",
        "        # Leave it blank if you prefer not to include headers\n",
        "        # pass\n"
      ],
      "metadata": {
        "id": "J1ODxq7gGORE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(model, test_sequences, test_labels):\n",
        "    \"\"\"\n",
        "    Evaluate the accuracy of the given model on the test dataset.\n",
        "\n",
        "    Parameters:\n",
        "        model: The trained model to evaluate.\n",
        "        num_features: The number of features in each data sample.\n",
        "        test_sequences: A list or array of test input data (features).\n",
        "        test_labels: A list or array of true labels corresponding to the test data.\n",
        "\n",
        "    Returns:\n",
        "        float: The accuracy of the model as a percentage.\n",
        "    \"\"\"\n",
        "    test_accuracy = model.score(test_sequences, test_labels)\n",
        "    return test_accuracy\n"
      ],
      "metadata": {
        "id": "Gawg5mCS8pC2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "# Lists to store accuracies over epochs\n",
        "global_model_weights = {}\n",
        "global_model_accuracy = []\n",
        "clients_train_accuracies = []  # List to store train accuracies per epoch per client\n",
        "clients_test_accuracies = []   # List to store test accuracies per epoch per client\n",
        "\n",
        "# Function to train the QNN model for one client\n",
        "def train_qnn_model(client_data,client_test_data, model=None):\n",
        "    #num_features = client_data[0][\"sequence\"].shape[0]  # Get the feature dimension\n",
        "    # Debug: Print the client data structure\n",
        "    #for i, client in enumerate(clients):\n",
        "        #print(f\"Client {i} Test Data: {client.test_data}\")\n",
        "        #print(f\"Test Data Length: {len(client.test_data)}\")\n",
        "\n",
        "    if model is None:\n",
        "        # Create a new QNN model if one doesn't exist\n",
        "        # Check if client_data is empty before creating the model\n",
        "        # Check if client_data is empty before creating the model\n",
        "        #if not client_data or all(not d for d in client_data):\n",
        "          #print(\"Client data is empty. Skipping training for this client.\")\n",
        "          #return None, None, None, None  # Or handle appropriately\n",
        "\n",
        "        model = initialize_qnn_model(client_data)\n",
        "\n",
        "    # Extract sequences and labels for training\n",
        "    train_sequences = [data_point[\"sequence\"] for data_point in client_data]\n",
        "    train_labels = [data_point[\"label\"] for data_point in client_data]\n",
        "\n",
        "    # Extract sequences and labels for testing\n",
        "    # Handle test data\n",
        "    if isinstance(client_test_data, dict):\n",
        "        # Single data point (dictionary format)\n",
        "        test_sequences = np.array([client_test_data[\"sequence\"]])\n",
        "        test_labels = np.array([client_test_data[\"label\"]])\n",
        "    else:\n",
        "        # List of dictionaries (multiple data points)\n",
        "        test_sequences = [data_point[\"sequence\"] for data_point in client_test_data]\n",
        "        test_labels = [data_point[\"label\"] for data_point in client_test_data]\n",
        "        test_sequences = np.array(test_sequences)\n",
        "        test_labels = np.array(test_labels)\n",
        "    # Debug: Print the first few test sequences and labels for verification\n",
        "    #print(\"First few test sequences:\", test_sequences[:2])\n",
        "    #print(\"First few test labels:\", test_labels[:2])\n",
        "    # Convert lists to NumPy arrays\n",
        "    train_sequences = np.array(train_sequences)\n",
        "    train_labels = np.array(train_labels)\n",
        "\n",
        "    # Check if train_labels is empty before proceeding with training\n",
        "    if len(train_labels) == 0:\n",
        "        print(\"Training labels are empty. Skipping training for this client.\")\n",
        "        return model, None, None\n",
        "\n",
        "    print(\"Training started...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the QNN model\n",
        "    model.fit(train_sequences, train_labels)\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"Training completed in {elapsed_time} seconds.\")\n",
        "\n",
        "    # Evaluate the model on training and test data\n",
        "    print(f\"SCORING MODEL\")\n",
        "    train_score_q = model.score(train_sequences, train_labels)\n",
        "    #test_score_q = model.score(test_sequences[:200], test_labels[:200])\n",
        "    test_score_q = model.score(test_sequences, test_labels)\n",
        "\n",
        "    return model, train_score_q, test_score_q, elapsed_time\n"
      ],
      "metadata": {
        "id": "3MIYwjjgH_Vs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multple Weighting mechanisms\n"
      ],
      "metadata": {
        "id": "RoETIMQ6vVBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_data_proportional_weights(client_data_sizes):\n",
        "    total_data_size = sum(client_data_sizes)\n",
        "    return [size / total_data_size for size in client_data_sizes]\n",
        "\n",
        "def compute_accuracy_based_weights(client_accuracies):\n",
        "    total_accuracy = sum(client_accuracies)\n",
        "    return [acc / total_accuracy for acc in client_accuracies]\n",
        "\n",
        "def compute_hybrid_weights(client_data_sizes, client_accuracies, alpha=0.5):\n",
        "    data_weights = compute_data_proportional_weights(client_data_sizes)\n",
        "    accuracy_weights = compute_accuracy_based_weights(client_accuracies)\n",
        "    return [\n",
        "        alpha * data_weight + (1 - alpha) * accuracy_weight\n",
        "        for data_weight, accuracy_weight in zip(data_weights, accuracy_weights)\n",
        "    ]\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def compute_entropy_based_weights(client_entropies):\n",
        "    inv_entropies = [1 / entropy for entropy in client_entropies]\n",
        "    total_inv_entropy = sum(inv_entropies)\n",
        "    return [inv_entropy / total_inv_entropy for inv_entropy in inv_entropies]\n",
        "\n",
        "def compute_fairness_weights(client_distributions, global_distribution):\n",
        "    import scipy.stats\n",
        "\n",
        "    kl_divergences = [\n",
        "        scipy.stats.entropy(client_dist, global_distribution)\n",
        "        for client_dist in client_distributions\n",
        "    ]\n",
        "    inv_kl_div = [1 / div for div in kl_divergences]\n",
        "    total_inv_kl = sum(inv_kl_div)\n",
        "    return [weight / total_inv_kl for weight in inv_kl_div]\n",
        "\n",
        "def compute_equal_weights(num_clients):\n",
        "    return [1 / num_clients] * num_clients\n",
        "\n"
      ],
      "metadata": {
        "id": "XX-ybkKADu3t"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_entropy_based_weights(client_data):\n",
        "    \"\"\"\n",
        "    Compute entropy-based weights for clients.\n",
        "    Entropy is calculated based on the distribution of labels in client data.\n",
        "\n",
        "    Parameters:\n",
        "    - client_data: List of data subsets for each client\n",
        "\n",
        "    Returns:\n",
        "    - List of normalized entropy weights\n",
        "    \"\"\"\n",
        "    import scipy.stats\n",
        "\n",
        "    entropies = []\n",
        "    for data in client_data:\n",
        "        labels = [sample[-1] for sample in data]  # Assuming labels are the last column\n",
        "        label_counts = {label: labels.count(label) for label in set(labels)}\n",
        "        probabilities = [count / len(labels) for count in label_counts.values()]\n",
        "        entropy = scipy.stats.entropy(probabilities)\n",
        "        entropies.append(entropy)\n",
        "\n",
        "    # Normalize entropies to sum to 1\n",
        "    total_entropy = sum(entropies)\n",
        "    return [e / total_entropy for e in entropies]\n"
      ],
      "metadata": {
        "id": "fywayb8dGzmU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_fairness_weights(client_contributions):\n",
        "    \"\"\"\n",
        "    Compute fairness-based weights for clients.\n",
        "    Fairness can be based on contribution equity or other criteria.\n",
        "\n",
        "    Parameters:\n",
        "    - client_contributions: List of client contributions (e.g., data size, model performance)\n",
        "\n",
        "    Returns:\n",
        "    - List of normalized fairness weights\n",
        "    \"\"\"\n",
        "    total_contribution = sum(client_contributions)\n",
        "    return [1.0 / contribution if contribution > 0 else 0 for contribution in client_contributions]\n"
      ],
      "metadata": {
        "id": "HHvxqlxnHAK8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def save_accuracies_to_csv(global_accuracy, clients_train_accuracies, clients_test_accuracies, filename=\"accuracies.csv\"):\n",
        "    \"\"\"\n",
        "    Saves accuracies to a CSV file.\n",
        "\n",
        "    Args:\n",
        "        global_accuracy (list): List of global model accuracies for each epoch.\n",
        "        clients_train_accuracies (list): List of lists, where each inner list contains train accuracies for a client over epochs.\n",
        "        clients_test_accuracies (list): List of lists, where each inner list contains test accuracies for a client over epochs.\n",
        "        filename (str, optional): Name of the CSV file. Defaults to \"accuracies.csv\".\n",
        "    \"\"\"\n",
        "    with open(filename, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "\n",
        "        # Write header\n",
        "        header = ['Epoch', 'Global Accuracy'] + [f'Client {i} Train Accuracy' for i in range(len(clients_train_accuracies))] + [f'Client {i} Test Accuracy' for i in range(len(clients_test_accuracies))]\n",
        "        writer.writerow(header)\n",
        "\n",
        "        # Write data rows\n",
        "        for epoch in range(len(global_accuracy)):\n",
        "            row = [epoch + 1, global_accuracy[epoch]]  # Epoch starts from 1\n",
        "\n",
        "            # Add client train accuracies for the epoch\n",
        "            row.extend([clients_train_accuracies[i][epoch] if epoch < len(clients_train_accuracies[i]) else '' for i in range(len(clients_train_accuracies))])\n",
        "\n",
        "            # Add client test accuracies for the epoch\n",
        "            row.extend([clients_test_accuracies[i][epoch] if epoch < len(clients_test_accuracies[i]) else '' for i in range(len(clients_test_accuracies))])\n",
        "\n",
        "            writer.writerow(row)"
      ],
      "metadata": {
        "id": "VGuZLTin1WqU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step to empty the CSV file before starting a new run\n",
        "def clear_csv_file():\n",
        "    \"\"\"\n",
        "    Clears the CSV file by overwriting it with headers or leaving it blank.\n",
        "    \"\"\"\n",
        "    with open(csv_file, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        # Uncomment the next line to write headers for the new run\n",
        "        writer.writerow(headers)\n",
        "        # Leave it blank if you prefer not to include headers\n",
        "        # pass\n"
      ],
      "metadata": {
        "id": "QkcYC4RJISi-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_aggregation(\n",
        "    epoch_weights,\n",
        "    client_data_sizes=None,\n",
        "    client_accuracies=None,\n",
        "    client_entropies=None,\n",
        "    global_distribution=None,\n",
        "    num_features=None,\n",
        "    weight_mechanism=\"fixed\",\n",
        "    **kwargs\n",
        "):\n",
        "    \"\"\"\n",
        "    Perform weighted aggregation of model weights with dynamic weighting mechanisms.\n",
        "\n",
        "    Parameters:\n",
        "    - epoch_weights: List of client weights for the epoch\n",
        "    - client_data_sizes: List of sizes of data owned by each client\n",
        "    - client_accuracies: List of accuracies achieved by each client\n",
        "    - client_entropies: List of entropies of client predictions\n",
        "    - global_distribution: Global data distribution for fairness-based weighting\n",
        "    - weight_mechanism: The weighting mechanism to use (\"data\", \"accuracy\", \"entropy\", \"fairness\", \"performance\", \"fixed\")\n",
        "    - num_features: The number of features in the model (added)\n",
        "    - kwargs: Additional parameters for specific weighting mechanisms\n",
        "\n",
        "    Returns:\n",
        "    - aggregated_weights: Aggregated model weights\n",
        "    \"\"\"\n",
        "    num_clients = len(epoch_weights)\n",
        "\n",
        "    # Determine weights based on mechanism\n",
        "    if weight_mechanism == \"data\":\n",
        "        if not client_data_sizes:\n",
        "            raise ValueError(\"Client data sizes must be provided for data-proportional weighting.\")\n",
        "        weights = compute_data_proportional_weights(client_data_sizes)\n",
        "\n",
        "    elif weight_mechanism == \"accuracy\":\n",
        "        if not client_accuracies:\n",
        "            raise ValueError(\"Client accuracies must be provided for accuracy-based weighting.\")\n",
        "        weights = compute_accuracy_based_weights(client_accuracies)\n",
        "\n",
        "    elif weight_mechanism == \"entropy\":\n",
        "        if not client_entropies:\n",
        "            raise ValueError(\"Client entropies must be provided for entropy-based weighting.\")\n",
        "        weights = compute_entropy_based_weights(client_entropies)\n",
        "\n",
        "    elif weight_mechanism == \"fairness\":\n",
        "        if not client_data_sizes or not global_distribution:\n",
        "            raise ValueError(\"Client data sizes and global distribution must be provided for fairness-based weighting.\")\n",
        "        weights = compute_fairness_weights(client_data_sizes, global_distribution)\n",
        "\n",
        "    elif weight_mechanism == \"performance\":\n",
        "        if not client_accuracies or len(client_accuracies) != num_clients:\n",
        "            raise ValueError(\"Client accuracies must be provided for performance-based weighting.\")\n",
        "        weights = client_accuracies  # Use accuracies directly as weights\n",
        "\n",
        "    elif weight_mechanism == \"hybrid\":\n",
        "        if not client_data_sizes or not client_accuracies:\n",
        "            raise ValueError(\"Both client data sizes and accuracies must be provided for hybrid weighting.\")\n",
        "        weights = compute_hybrid_weights(client_data_sizes, client_accuracies, alpha=kwargs.get(\"alpha\", 0.5))\n",
        "\n",
        "\n",
        "    elif weight_mechanism == \"fixed\":\n",
        "        best_client_index = kwargs.get(\"best_client_index\", 0)\n",
        "        best_client_weight_factor = kwargs.get(\"best_client_weight_factor\", 1.5)\n",
        "        weights = [best_client_weight_factor if i == best_client_index else 1 for i in range(num_clients)]\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown weighting mechanism: {weight_mechanism}\")\n",
        "\n",
        "    # Normalize weights\n",
        "    total_weight = sum(weights)\n",
        "    weights = [w / total_weight for w in weights]\n",
        "\n",
        "    # Perform weighted aggregation\n",
        "    aggregated_weights = np.zeros_like(epoch_weights[0])\n",
        "    for i, client_weights in enumerate(epoch_weights):\n",
        "        aggregated_weights += weights[i] * np.array(client_weights)\n",
        "\n",
        "    return aggregated_weights\n",
        "import csv\n",
        "from google.colab import drive\n",
        "\n",
        "def reset_state():\n",
        "    # Reset the objective value, learning rate, and perturbation after each client\n",
        "    global objective_func_vals, learning_rates, perturbations\n",
        "    objective_func_vals = []  # Reset objective values\n",
        "    learning_rates = []  # Reset learning rates\n",
        "    perturbations = []  # Reset perturbations\n",
        "# Function to reset callback graph state after each round\n",
        "def reset_callback_graph():\n",
        "    global gradient_moving_avg, learning_rates, perturbations\n",
        "\n",
        "    # Reset the state variables to start fresh for the next round\n",
        "    gradient_moving_avg = np.zeros_like(gradient_moving_avg)  # Reset gradient moving average\n",
        "    learning_rates = [initial_learning_rate]  # Reset learning rates list to initial value\n",
        "    perturbations = [initial_perturbation]  # Reset perturbations list to initial value\n",
        "\n",
        "# Mount Google Drive if not already mounted\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to store the best client's data\n",
        "best_csv_file = '/content/drive/My Drive/QFL_Genome_Best_Client31.03.2025.csv'\n",
        "\n",
        "# Write headers to the best client CSV file\n",
        "bestheader = [\"Federated Round\", \"Client Number\"]\n",
        "\n",
        "with open(best_csv_file, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(bestheader)\n",
        "\n",
        "# Function to update the best client data\n",
        "def save_best_client_results(federated_round,best_client_index):\n",
        "    \"\"\"\n",
        "    Save the best client's data to a separate CSV file.\n",
        "    :param best_data: Dictionary containing the best client's data.\n",
        "    \"\"\"\n",
        "    with open(best_csv_file, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([federated_round,\n",
        "           best_client_index\n",
        "\n",
        "        ])\n",
        "# Clear the CSV file for a new run\n",
        "#clear_csv_file()\n",
        "\n",
        "global_model_weights = [None] * num_epochs # Initialize as a list to store weights for each epoch\n",
        "global_model_accuracy = []\n",
        "# Initialize client_train_accuracies and client_test_accuracies:\n",
        "clients_train_accuracies = [[] for _ in range(num_clients)]\n",
        "clients_test_accuracies = [[] for _ in range(num_clients)]\n",
        "# Example usage in the federated learning loop\n",
        "for epoch in range(num_epochs):\n",
        "    global_model_weights[epoch] = []\n",
        "    epoch_weights = []\n",
        "\n",
        "    epoch_train_accuracies = []\n",
        "    epoch_test_accuracies = []\n",
        "    print(\"\\n\")\n",
        "    print(f\"Epoch: {epoch}\")\n",
        "\n",
        "    best_client_index = -1\n",
        "    best_client_accuracy = -1\n",
        "\n",
        "    # Train each client\n",
        "    for index, client in enumerate(clients):\n",
        "        print(\"\\n\")\n",
        "        print(f\"Training Client {index}\")\n",
        "        reset_state()\n",
        "\n",
        "        model, train_score_q, test_score_q, train_time = train_qnn_model(client.data[epoch], client.test_data, model=client.primary_model)\n",
        "        client.primary_model = model\n",
        "\n",
        "        #client.train_scores.append(train_score_q)\n",
        "        #client.test_scores.append(test_score_q)\n",
        "\n",
        "        num_features = client.data[epoch][0][\"sequence\"].shape[0]\n",
        "\n",
        "        print(f\"Client {index} Train Score: {train_score_q}\")\n",
        "        print(f\"Client {index} Test Score: {test_score_q}\")\n",
        "\n",
        "        # Append scores to clients_train_accuracies and clients_test_accuracies:\n",
        "        clients_train_accuracies[index].append(train_score_q)\n",
        "        clients_test_accuracies[index].append(test_score_q)\n",
        "\n",
        "        epoch_train_accuracies.append(train_score_q)\n",
        "        epoch_test_accuracies.append(test_score_q)\n",
        "\n",
        "        if test_score_q is not None and test_score_q > best_client_accuracy:\n",
        "            best_client_accuracy = test_score_q\n",
        "            best_client_index = index\n",
        "            best_client_model = model  # Directly store the best client's model\n",
        "\n",
        "        # Collect model weights\n",
        "        epoch_weights.append(model.weights)\n",
        "\n",
        "    save_best_client_results(epoch,best_client_index)  # Save to best client CSV\n",
        "    print(f\"Best client for epoch {epoch} is Client {best_client_index} with test accuracy {best_client_accuracy:.2f}\")\n",
        "\n",
        "    # Treat the best client's model as the global model for the next round\n",
        "    global_model = best_client_model\n",
        "    # Update all clients with the global model\n",
        "    for index, client in enumerate(clients):\n",
        "        client.primary_model = global_model\n",
        "\n",
        "    # Evaluate the global model on the new test data\n",
        "    global_accuracy = get_accuracy(global_model, test_sequences, test_labels)\n",
        "    global_model_accuracy.append(global_accuracy)\n",
        "\n",
        "    clients_train_accuracies.append(epoch_train_accuracies)\n",
        "    clients_test_accuracies.append(epoch_test_accuracies)\n",
        "\n",
        "    print(f\"Global Model Accuracy in Epoch {epoch}: {global_accuracy:.2f}\")\n",
        "    print(\"----------------------------------------------------------\")\n",
        "\n",
        "\n",
        "    # Save results for the current iteration of the client in the federated round\n",
        "    from google.colab import drive\n",
        "\n",
        "    # Step 1: Mount Google Drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Step 2: Define the save path in Google Drive\n",
        "    save_path = '/content/drive/MyDrive/QFL_Genome_global_31.03.2025.csv'\n",
        "\n",
        "\n",
        "    # Save accuracies to CSV after each epoch (or at the end of all epochs)\n",
        "    save_accuracies_to_csv(global_model_accuracy, clients_train_accuracies, clients_test_accuracies, filename=save_path)\n",
        "    # After each round, reset callback state to prepare for the next round\n",
        "\n",
        "    print(f\"File saved to {save_path}\")\n",
        "    '''\n",
        "    # Choose weighting mechanism\n",
        "    weight_mechanism = \"fixed\"  # Can be \"fixed\", \"performance\", \"dynamic\", \"entropy\", or \"fairness\"\n",
        "\n",
        "    if weight_mechanism == \"fixed\":\n",
        "        aggregated_weights = weighted_aggregation(\n",
        "        epoch_weights=epoch_weights,\n",
        "        client_data_sizes=[len(client.data[epoch]) for client in clients],\n",
        "        client_accuracies=epoch_test_accuracies,\n",
        "        client_entropies=None,  # Add if available\n",
        "        global_distribution=None,  # Add if required\n",
        "        weight_mechanism=weight_mechanism,\n",
        "        num_features=num_features,\n",
        "        best_client_index=best_client_index,  # Only for \"fixed\"\n",
        "        best_client_weight_factor=1.5  # Only for \"fixed\"\n",
        ")\n",
        "\n",
        "\n",
        "    elif weight_mechanism == \"performance\":\n",
        "        aggregated_weights = weighted_aggregation(\n",
        "        epoch_weights=epoch_weights,\n",
        "        client_data_sizes=[len(client.data[epoch]) for client in clients],\n",
        "        client_accuracies=epoch_test_accuracies,\n",
        "        client_entropies=None,  # Add if available\n",
        "        global_distribution=None,  # Add if required\n",
        "        weight_mechanism=weight_mechanism,\n",
        "        num_features=num_features,\n",
        "        best_client_index=best_client_index,  # Only for \"fixed\"\n",
        "        best_client_weight_factor=1.5  # Only for \"fixed\"\n",
        ")\n",
        "\n",
        "    elif weight_mechanism == \"dynamic\":\n",
        "        aggregated_weights = weighted_aggregation(\n",
        "            epoch_weights,\n",
        "            best_client_index,\n",
        "            weight_mechanism=weight_mechanism,\n",
        "            accuracies=epoch_test_accuracies,\n",
        "            beta=1.0,\n",
        "            num_features=num_features  # Pass num_features here\n",
        "        )\n",
        "\n",
        "    elif weight_mechanism == \"entropy\":\n",
        "        client_entropies = compute_entropy_based_weights(client.data[epoch])  # Compute entropy weights for clients\n",
        "        aggregated_weights = weighted_aggregation(\n",
        "            epoch_weights,\n",
        "            best_client_index,\n",
        "            weight_mechanism=weight_mechanism,\n",
        "            entropies=client_entropies,  # Pass entropy-based weights\n",
        "            num_features=num_features  # Pass num_features here\n",
        "        )\n",
        "\n",
        "    elif weight_mechanism == \"fairness\":\n",
        "        fairness_weights = compute_fairness_weights(client_contributions)  # Compute fairness-based weights\n",
        "        aggregated_weights = weighted_aggregation(\n",
        "            epoch_weights,\n",
        "            best_client_index,\n",
        "            weight_mechanism=weight_mechanism,\n",
        "            fairness_weights=fairness_weights,  # Pass fairness-based weights\n",
        "            num_features=num_features  # Pass num_features here\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown weighting mechanism: {weight_mechanism}\")\n",
        "\n",
        "    '''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh1LV8SDvSc3",
        "outputId": "f2f5197d-2ed9-4831-bf40-bf1431163942"
      },
      "execution_count": 25,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "\n",
            "Epoch: 0\n",
            "\n",
            "\n",
            "Training Client 0\n",
            "Number of features (input dimension): 5\n",
            "Number of circuit parameters: 25\n",
            "Training started...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-14-6e5ad0ddc26c>:45: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
            "  sampler_qnn = SamplerQNN(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training completed in 97.43499279022217 seconds.\n",
            "SCORING MODEL\n",
            "Client 0 Train Score: 0.47\n",
            "Client 0 Test Score: 0.453\n",
            "\n",
            "\n",
            "Training Client 1\n",
            "Number of features (input dimension): 5\n",
            "Number of circuit parameters: 25\n",
            "Training started...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-14-6e5ad0ddc26c>:45: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
            "  sampler_qnn = SamplerQNN(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training completed in 96.13067197799683 seconds.\n",
            "SCORING MODEL\n",
            "Client 1 Train Score: 0.5\n",
            "Client 1 Test Score: 0.529\n",
            "\n",
            "\n",
            "Training Client 2\n",
            "Number of features (input dimension): 5\n",
            "Number of circuit parameters: 25\n",
            "Training started...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-14-6e5ad0ddc26c>:45: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
            "  sampler_qnn = SamplerQNN(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training completed in 92.78450918197632 seconds.\n",
            "SCORING MODEL\n",
            "Client 2 Train Score: 0.58\n",
            "Client 2 Test Score: 0.529\n",
            "\n",
            "\n",
            "Training Client 3\n",
            "Number of features (input dimension): 5\n",
            "Number of circuit parameters: 25\n",
            "Training started...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-14-6e5ad0ddc26c>:45: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
            "  sampler_qnn = SamplerQNN(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training completed in 94.40211153030396 seconds.\n",
            "SCORING MODEL\n",
            "Client 3 Train Score: 0.57\n",
            "Client 3 Test Score: 0.545\n",
            "\n",
            "\n",
            "Training Client 4\n",
            "Number of features (input dimension): 5\n",
            "Number of circuit parameters: 25\n",
            "Training started...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-14-6e5ad0ddc26c>:45: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
            "  sampler_qnn = SamplerQNN(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed in 92.01271080970764 seconds.\n",
            "SCORING MODEL\n",
            "Client 4 Train Score: 0.46\n",
            "Client 4 Test Score: 0.465\n",
            "Best client for epoch 0 is Client 3 with test accuracy 0.55\n",
            "Global Model Accuracy in Epoch 0: 0.53\n",
            "----------------------------------------------------------\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File saved to /content/drive/MyDrive/QFL_Genome_global_31.03.2025.csv\n",
            "\n",
            "\n",
            "Epoch: 1\n",
            "\n",
            "\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 93.04899096488953 seconds.\n",
            "SCORING MODEL\n",
            "Client 0 Train Score: 0.6\n",
            "Client 0 Test Score: 0.565\n",
            "\n",
            "\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 92.08372187614441 seconds.\n",
            "SCORING MODEL\n",
            "Client 1 Train Score: 0.59\n",
            "Client 1 Test Score: 0.52\n",
            "\n",
            "\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 93.05117297172546 seconds.\n",
            "SCORING MODEL\n",
            "Client 2 Train Score: 0.62\n",
            "Client 2 Test Score: 0.507\n",
            "\n",
            "\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 92.98480296134949 seconds.\n",
            "SCORING MODEL\n",
            "Client 3 Train Score: 0.55\n",
            "Client 3 Test Score: 0.569\n",
            "\n",
            "\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 91.36246919631958 seconds.\n",
            "SCORING MODEL\n",
            "Client 4 Train Score: 0.56\n",
            "Client 4 Test Score: 0.52\n",
            "Best client for epoch 1 is Client 3 with test accuracy 0.57\n",
            "Global Model Accuracy in Epoch 1: 0.53\n",
            "----------------------------------------------------------\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File saved to /content/drive/MyDrive/QFL_Genome_global_31.03.2025.csv\n",
            "\n",
            "\n",
            "Epoch: 2\n",
            "\n",
            "\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 92.72392892837524 seconds.\n",
            "SCORING MODEL\n",
            "Client 0 Train Score: 0.51\n",
            "Client 0 Test Score: 0.579\n",
            "\n",
            "\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 91.41081595420837 seconds.\n",
            "SCORING MODEL\n",
            "Client 1 Train Score: 0.48\n",
            "Client 1 Test Score: 0.568\n",
            "\n",
            "\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 94.43055582046509 seconds.\n",
            "SCORING MODEL\n",
            "Client 2 Train Score: 0.53\n",
            "Client 2 Test Score: 0.555\n",
            "\n",
            "\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 90.1954779624939 seconds.\n",
            "SCORING MODEL\n",
            "Client 3 Train Score: 0.54\n",
            "Client 3 Test Score: 0.547\n",
            "\n",
            "\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 90.19283628463745 seconds.\n",
            "SCORING MODEL\n",
            "Client 4 Train Score: 0.62\n",
            "Client 4 Test Score: 0.552\n",
            "Best client for epoch 2 is Client 0 with test accuracy 0.58\n",
            "Global Model Accuracy in Epoch 2: 0.56\n",
            "----------------------------------------------------------\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File saved to /content/drive/MyDrive/QFL_Genome_global_31.03.2025.csv\n",
            "\n",
            "\n",
            "Epoch: 3\n",
            "\n",
            "\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 90.94708514213562 seconds.\n",
            "SCORING MODEL\n",
            "Client 0 Train Score: 0.58\n",
            "Client 0 Test Score: 0.565\n",
            "\n",
            "\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 93.49758505821228 seconds.\n",
            "SCORING MODEL\n",
            "Client 1 Train Score: 0.56\n",
            "Client 1 Test Score: 0.587\n",
            "\n",
            "\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 92.71854853630066 seconds.\n",
            "SCORING MODEL\n",
            "Client 2 Train Score: 0.62\n",
            "Client 2 Test Score: 0.504\n",
            "\n",
            "\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 94.0738594532013 seconds.\n",
            "SCORING MODEL\n",
            "Client 3 Train Score: 0.54\n",
            "Client 3 Test Score: 0.562\n",
            "\n",
            "\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 91.72662878036499 seconds.\n",
            "SCORING MODEL\n",
            "Client 4 Train Score: 0.54\n",
            "Client 4 Test Score: 0.532\n",
            "Best client for epoch 3 is Client 1 with test accuracy 0.59\n",
            "Global Model Accuracy in Epoch 3: 0.54\n",
            "----------------------------------------------------------\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File saved to /content/drive/MyDrive/QFL_Genome_global_31.03.2025.csv\n",
            "\n",
            "\n",
            "Epoch: 4\n",
            "\n",
            "\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 93.54542207717896 seconds.\n",
            "SCORING MODEL\n",
            "Client 0 Train Score: 0.54\n",
            "Client 0 Test Score: 0.576\n",
            "\n",
            "\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 93.08948588371277 seconds.\n",
            "SCORING MODEL\n",
            "Client 1 Train Score: 0.65\n",
            "Client 1 Test Score: 0.542\n",
            "\n",
            "\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 94.62803149223328 seconds.\n",
            "SCORING MODEL\n",
            "Client 2 Train Score: 0.57\n",
            "Client 2 Test Score: 0.535\n",
            "\n",
            "\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 92.993488073349 seconds.\n",
            "SCORING MODEL\n",
            "Client 3 Train Score: 0.53\n",
            "Client 3 Test Score: 0.573\n",
            "\n",
            "\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 93.24693512916565 seconds.\n",
            "SCORING MODEL\n",
            "Client 4 Train Score: 0.53\n",
            "Client 4 Test Score: 0.548\n",
            "Best client for epoch 4 is Client 0 with test accuracy 0.58\n",
            "Global Model Accuracy in Epoch 4: 0.56\n",
            "----------------------------------------------------------\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File saved to /content/drive/MyDrive/QFL_Genome_global_31.03.2025.csv\n",
            "\n",
            "\n",
            "Epoch: 5\n",
            "\n",
            "\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 90.89573645591736 seconds.\n",
            "SCORING MODEL\n",
            "Client 0 Train Score: 0.6\n",
            "Client 0 Test Score: 0.524\n",
            "\n",
            "\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 92.86397004127502 seconds.\n",
            "SCORING MODEL\n",
            "Client 1 Train Score: 0.59\n",
            "Client 1 Test Score: 0.582\n",
            "\n",
            "\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 91.50634479522705 seconds.\n",
            "SCORING MODEL\n",
            "Client 2 Train Score: 0.52\n",
            "Client 2 Test Score: 0.523\n",
            "\n",
            "\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 92.2171881198883 seconds.\n",
            "SCORING MODEL\n",
            "Client 3 Train Score: 0.63\n",
            "Client 3 Test Score: 0.573\n",
            "\n",
            "\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 91.15624332427979 seconds.\n",
            "SCORING MODEL\n",
            "Client 4 Train Score: 0.53\n",
            "Client 4 Test Score: 0.543\n",
            "Best client for epoch 5 is Client 1 with test accuracy 0.58\n",
            "Global Model Accuracy in Epoch 5: 0.55\n",
            "----------------------------------------------------------\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File saved to /content/drive/MyDrive/QFL_Genome_global_31.03.2025.csv\n",
            "\n",
            "\n",
            "Epoch: 6\n",
            "\n",
            "\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 92.62756419181824 seconds.\n",
            "SCORING MODEL\n",
            "Client 0 Train Score: 0.54\n",
            "Client 0 Test Score: 0.552\n",
            "\n",
            "\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 93.46309471130371 seconds.\n",
            "SCORING MODEL\n",
            "Client 1 Train Score: 0.54\n",
            "Client 1 Test Score: 0.572\n",
            "\n",
            "\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 92.70578217506409 seconds.\n",
            "SCORING MODEL\n",
            "Client 2 Train Score: 0.54\n",
            "Client 2 Test Score: 0.535\n",
            "\n",
            "\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 93.39297199249268 seconds.\n",
            "SCORING MODEL\n",
            "Client 3 Train Score: 0.53\n",
            "Client 3 Test Score: 0.564\n",
            "\n",
            "\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 93.49050688743591 seconds.\n",
            "SCORING MODEL\n",
            "Client 4 Train Score: 0.6\n",
            "Client 4 Test Score: 0.511\n",
            "Best client for epoch 6 is Client 1 with test accuracy 0.57\n",
            "Global Model Accuracy in Epoch 6: 0.52\n",
            "----------------------------------------------------------\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File saved to /content/drive/MyDrive/QFL_Genome_global_31.03.2025.csv\n",
            "\n",
            "\n",
            "Epoch: 7\n",
            "\n",
            "\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 92.30178117752075 seconds.\n",
            "SCORING MODEL\n",
            "Client 0 Train Score: 0.55\n",
            "Client 0 Test Score: 0.58\n",
            "\n",
            "\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 93.12684869766235 seconds.\n",
            "SCORING MODEL\n",
            "Client 1 Train Score: 0.59\n",
            "Client 1 Test Score: 0.519\n",
            "\n",
            "\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 92.78836297988892 seconds.\n",
            "SCORING MODEL\n",
            "Client 2 Train Score: 0.55\n",
            "Client 2 Test Score: 0.536\n",
            "\n",
            "\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 90.01948261260986 seconds.\n",
            "SCORING MODEL\n",
            "Client 3 Train Score: 0.49\n",
            "Client 3 Test Score: 0.579\n",
            "\n",
            "\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 91.19828772544861 seconds.\n",
            "SCORING MODEL\n",
            "Client 4 Train Score: 0.54\n",
            "Client 4 Test Score: 0.545\n",
            "Best client for epoch 7 is Client 0 with test accuracy 0.58\n",
            "Global Model Accuracy in Epoch 7: 0.55\n",
            "----------------------------------------------------------\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File saved to /content/drive/MyDrive/QFL_Genome_global_31.03.2025.csv\n",
            "\n",
            "\n",
            "Epoch: 8\n",
            "\n",
            "\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 90.80707502365112 seconds.\n",
            "SCORING MODEL\n",
            "Client 0 Train Score: 0.58\n",
            "Client 0 Test Score: 0.546\n",
            "\n",
            "\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 92.01373815536499 seconds.\n",
            "SCORING MODEL\n",
            "Client 1 Train Score: 0.58\n",
            "Client 1 Test Score: 0.52\n",
            "\n",
            "\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 91.81047940254211 seconds.\n",
            "SCORING MODEL\n",
            "Client 2 Train Score: 0.52\n",
            "Client 2 Test Score: 0.535\n",
            "\n",
            "\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 92.9118082523346 seconds.\n",
            "SCORING MODEL\n",
            "Client 3 Train Score: 0.54\n",
            "Client 3 Test Score: 0.553\n",
            "\n",
            "\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 94.41686248779297 seconds.\n",
            "SCORING MODEL\n",
            "Client 4 Train Score: 0.59\n",
            "Client 4 Test Score: 0.539\n",
            "Best client for epoch 8 is Client 3 with test accuracy 0.55\n",
            "Global Model Accuracy in Epoch 8: 0.55\n",
            "----------------------------------------------------------\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File saved to /content/drive/MyDrive/QFL_Genome_global_31.03.2025.csv\n",
            "\n",
            "\n",
            "Epoch: 9\n",
            "\n",
            "\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 94.13558149337769 seconds.\n",
            "SCORING MODEL\n",
            "Client 0 Train Score: 0.56\n",
            "Client 0 Test Score: 0.528\n",
            "\n",
            "\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 93.0693793296814 seconds.\n",
            "SCORING MODEL\n",
            "Client 1 Train Score: 0.55\n",
            "Client 1 Test Score: 0.531\n",
            "\n",
            "\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 92.65768313407898 seconds.\n",
            "SCORING MODEL\n",
            "Client 2 Train Score: 0.53\n",
            "Client 2 Test Score: 0.534\n",
            "\n",
            "\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 91.26525664329529 seconds.\n",
            "SCORING MODEL\n",
            "Client 3 Train Score: 0.6\n",
            "Client 3 Test Score: 0.547\n",
            "\n",
            "\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 90.60832500457764 seconds.\n",
            "SCORING MODEL\n",
            "Client 4 Train Score: 0.59\n",
            "Client 4 Test Score: 0.57\n",
            "Best client for epoch 9 is Client 4 with test accuracy 0.57\n",
            "Global Model Accuracy in Epoch 9: 0.58\n",
            "----------------------------------------------------------\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File saved to /content/drive/MyDrive/QFL_Genome_global_31.03.2025.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    epoch_weights = []\n",
        "    epoch_train_accuracies = []\n",
        "    epoch_test_accuracies = []\n",
        "\n",
        "    print(f\"\\nEpoch: {epoch}\")\n",
        "\n",
        "    # Train each client\n",
        "    for index, client in enumerate(clients):\n",
        "        print(f\"\\nTraining Client {index}\")\n",
        "        model, train_score_q, test_score_q, train_time = train_qnn_model(\n",
        "            client.data[epoch], client.test_data, model=client.primary_model\n",
        "        )\n",
        "        client.primary_model = model\n",
        "        epoch_train_accuracies.append(train_score_q)\n",
        "        epoch_test_accuracies.append(test_score_q)\n",
        "        epoch_weights.append(model.weights)\n",
        "\n",
        "    # Define client data sizes\n",
        "    client_data_sizes = [len(client.data[epoch]) for client in clients]\n",
        "\n",
        "    # Aggregate weights using hybrid weighting\n",
        "    aggregated_weights = weighted_aggregation(\n",
        "        epoch_weights=epoch_weights,\n",
        "        client_data_sizes=client_data_sizes,\n",
        "        client_accuracies=epoch_test_accuracies,\n",
        "        weight_mechanism=\"hybrid\",\n",
        "        alpha=0.7  # Set the alpha value (e.g., 0.7 for 70% data, 30% accuracy)\n",
        "    )\n",
        "\n",
        "    # Update global model\n",
        "    global_model_weights[epoch] = aggregated_weights\n",
        "    epoch_global_Model = create_model_with_weights(global_model_weights[epoch], num_features)\n",
        "\n",
        "    # Update client models\n",
        "    for client in clients:\n",
        "        client.primary_model = epoch_global_Model\n",
        "\n",
        "    # Evaluate global model\n",
        "    global_accuracy = getAccuracy(epoch_global_Model, num_features, test_sequences, test_labels)\n",
        "    global_model_accuracy.append(global_accuracy)\n",
        "\n",
        "    print(f\"Global Model Accuracy in Epoch {epoch}: {global_accuracy:.2f}\")\n",
        "    print(\"----------------------------------------------------------\")\n"
      ],
      "metadata": {
        "id": "0TCKioa7HTjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M2luD4eSGUHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "filename = 'accuracies.csv'\n",
        "data = pd.read_csv(filename)\n",
        "\n",
        "# Load the CSV file\n",
        "#filename = 'bestclient.csv'\n",
        "#datab = pd.read_csv(filename)\n",
        "\n",
        "# Extract the relevant columns for plotting\n",
        "epochs = data['Epoch']\n",
        "global_accuracy = data['Global Accuracy']\n",
        "client_train_accuracies = data.filter(like='Train Accuracy').values\n",
        "client_test_accuracies = data.filter(like='Test Accuracy').values\n",
        "\n",
        "# Extract the relevant columns for plotting\n",
        "bepochs = datab['Epoch']\n",
        "bglobal_accuracy = datab['Global Accuracy']\n",
        "bclient_train_accuracies = datab.filter(like='Train Accuracy').values\n",
        "bclient_test_accuracies = datab.filter(like='Test Accuracy').values\n",
        "\n",
        "# Plot Global Accuracy over Epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, global_accuracy, label='Global Accuracy', color='blue', marker='o')\n",
        "plt.plot(bepochs, bglobal_accuracy, label='Global Accuracy', color='red', marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Global Accuracy')\n",
        "plt.title('Global Accuracy Over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "# Plot Global Accuracy over Epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(bepochs, bglobal_accuracy, label='Global Accuracy', color='blue', marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Global Accuracy')\n",
        "plt.title('Global Accuracy Over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Plot Train Accuracies for all clients over Epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "for i in range(client_train_accuracies.shape[1]):\n",
        "    plt.plot(epochs, client_train_accuracies[:, i], label=f'Client {i} Train Accuracy', marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Train Accuracy')\n",
        "plt.title('Train Accuracies for All Clients Over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Plot Test Accuracies for all clients over Epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "for i in range(client_test_accuracies.shape[1]):\n",
        "    plt.plot(epochs, client_test_accuracies[:, i], label=f'Client {i} Test Accuracy', marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Test Accuracy')\n",
        "plt.title('Test Accuracies for All Clients Over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uFJnhIdQY8dl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}